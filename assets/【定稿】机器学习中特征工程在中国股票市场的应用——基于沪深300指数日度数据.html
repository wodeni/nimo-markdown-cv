<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>【定稿】机器学习中特征工程在中国股票市场的应用——基于沪深300指数日度数据.md</title><link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}.CodeMirror { height: auto; }
.CodeMirror-scroll { overflow-y: hidden; overflow-x: auto; }
.CodeMirror-lines { padding: 4px 0px; }
.CodeMirror pre { }
.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler { background-color: white; }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background-color: rgb(247, 247, 247); white-space: nowrap; }
.CodeMirror-linenumbers { }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.CodeMirror div.CodeMirror-cursor { border-left: 1px solid black; z-index: 3; }
.CodeMirror div.CodeMirror-secondarycursor { border-left: 1px solid silver; }
.CodeMirror.cm-keymap-fat-cursor div.CodeMirror-cursor { width: auto; border: 0px; background: rgb(119, 238, 119); z-index: 1; }
.CodeMirror div.CodeMirror-cursor.CodeMirror-overwrite { }
.cm-tab { display: inline-block; }
.cm-s-typora-default .cm-header, .cm-s-typora-default .cm-property { color: rgb(217, 79, 138); }
.cm-s-typora-default pre.cm-header1:not(.cm-atom) :not(.cm-overlay) { font-size: 2rem; line-height: 2rem; }
.cm-s-typora-default pre.cm-header2:not(.cm-atom) :not(.cm-overlay) { font-size: 1.4rem; line-height: 1.4rem; }
.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number { color: rgb(149, 132, 134); }
.cm-s-typora-default .cm-table-row, .cm-s-typora-default .cm-block-start { font-family: monospace; }
.cm-s-typora-default .cm-comment, .cm-s-typora-default .cm-code { color: rgb(74, 90, 159); font-family: monospace; }
.cm-s-typora-default .cm-tag { color: rgb(169, 68, 66); }
.cm-s-typora-default .cm-string { color: rgb(126, 134, 169); }
.cm-s-typora-default .cm-link { color: rgb(196, 122, 15); text-decoration: underline; }
.cm-s-typora-default .cm-variable-2, .cm-s-typora-default .cm-variable-1 { color: inherit; }
.cm-s-typora-default .cm-overlay { font-size: 1rem; font-family: monospace; }
.CodeMirror.cm-s-typora-default div.CodeMirror-cursor { border-left: 3px solid rgb(228, 98, 154); }
.cm-s-typora-default .CodeMirror-activeline-background { left: -60px; right: -30px; background: rgba(204, 204, 204, 0.2); }
.cm-s-typora-default .CodeMirror-gutters { border-right: none; background-color: inherit; }
.cm-s-typora-default .cm-trailing-space-new-line::after, .cm-startspace::after, .cm-starttab .cm-tab::after { content: "•"; position: absolute; left: 0px; opacity: 0; font-family: LetterGothicStd, monospace; }
.os-windows .cm-startspace::after, .os-windows .cm-starttab .cm-tab::after { left: -0.1em; }
.cm-starttab .cm-tab::after { content: " "; }
.cm-startspace, .cm-tab, .cm-starttab, .cm-trailing-space-a, .cm-trailing-space-b, .cm-trailing-space-new-line { font-family: monospace; position: relative; }
.cm-s-typora-default .cm-trailing-space-new-line::after { content: "↓"; opacity: 0.3; }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: black; }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-property { color: black; }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: blue; }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: bold; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: rgb(255, 0, 0); }
.cm-invalidchar { color: rgb(255, 0, 0); }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { margin-bottom: -30px; margin-right: -30px; padding-bottom: 30px; padding-right: 30px; height: 100%; outline: none; position: relative; box-sizing: content-box; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler { position: absolute; z-index: 6; display: none; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow-x: hidden; overflow-y: scroll; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow-y: hidden; overflow-x: scroll; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 30px; z-index: 3; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: transparent; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; word-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { word-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; left: 0px; right: 0px; top: 0px; bottom: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-widget { }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.CodeMirror-selected { background: rgb(217, 217, 217); }
.CodeMirror-focused .CodeMirror-selected { background: rgb(215, 212, 240); }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
.CodeMirror span { }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}
.CodeMirror-lint-markers { width: 16px; }
.CodeMirror-lint-tooltip { background-color: infobackground; border: 1px solid black; border-radius: 4px; color: infotext; font-family: monospace; overflow: hidden; padding: 2px 5px; position: fixed; white-space: pre-wrap; z-index: 10000; max-width: 600px; opacity: 0; transition: opacity 0.4s; font-size: 0.8em; }
.CodeMirror-lint-mark-error, .CodeMirror-lint-mark-warning { background-position: left bottom; background-repeat: repeat-x; }
.CodeMirror-lint-mark-error { background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAQAAAADCAYAAAC09K7GAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9sJDw4cOCW1/KIAAAAZdEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIEdJTVBXgQ4XAAAAHElEQVQI12NggIL/DAz/GdA5/xkY/qPKMDAwAADLZwf5rvm+LQAAAABJRU5ErkJggg=="); }
.CodeMirror-lint-marker-error, .CodeMirror-lint-marker-warning { background-position: center center; background-repeat: no-repeat; cursor: pointer; display: inline-block; height: 16px; width: 16px; vertical-align: middle; position: relative; }
.CodeMirror-lint-message-error, .CodeMirror-lint-message-warning { padding-left: 18px; background-position: left top; background-repeat: no-repeat; }
.CodeMirror-lint-marker-error, .CodeMirror-lint-message-error { background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAHlBMVEW7AAC7AACxAAC7AAC7AAAAAAC4AAC5AAD///+7AAAUdclpAAAABnRSTlMXnORSiwCK0ZKSAAAATUlEQVR42mWPOQ7AQAgDuQLx/z8csYRmPRIFIwRGnosRrpamvkKi0FTIiMASR3hhKW+hAN6/tIWhu9PDWiTGNEkTtIOucA5Oyr9ckPgAWm0GPBog6v4AAAAASUVORK5CYII="); }
.CodeMirror-lint-marker-warning, .CodeMirror-lint-message-warning { background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAANlBMVEX/uwDvrwD/uwD/uwD/uwD/uwD/uwD/uwD/uwD6twD/uwAAAADurwD2tQD7uAD+ugAAAAD/uwDhmeTRAAAADHRSTlMJ8mN1EYcbmiixgACm7WbuAAAAVklEQVR42n3PUQqAIBBFUU1LLc3u/jdbOJoW1P08DA9Gba8+YWJ6gNJoNYIBzAA2chBth5kLmG9YUoG0NHAUwFXwO9LuBQL1giCQb8gC9Oro2vp5rncCIY8L8uEx5ZkAAAAASUVORK5CYII="); }
.CodeMirror-lint-marker-multiple { background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAHCAMAAADzjKfhAAAACVBMVEUAAAAAAAC/v7914kyHAAAAAXRSTlMAQObYZgAAACNJREFUeNo1ioEJAAAIwmz/H90iFFSGJgFMe3gaLZ0od+9/AQZ0ADosbYraAAAAAElFTkSuQmCC"); background-repeat: no-repeat; background-position: right bottom; width: 100%; height: 100%; }


html { font-size: 14px; background-color: rgb(255, 255, 255); color: rgb(51, 51, 51); }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { background: rgb(181, 214, 252); text-shadow: none; }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; padding-bottom: 70px; white-space: pre-wrap; overflow-x: visible; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
.typora-export #write { margin: 0px auto; }
#write > p:first-child, #write > ul:first-child, #write > ol:first-child, #write > pre:first-child, #write > blockquote:first-child, #write > div:first-child, #write > table:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
input, button, select, textarea { color: inherit; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; font-size: inherit; line-height: inherit; font-family: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
::before, ::after, * { box-sizing: border-box; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write div, #write pre { width: inherit; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6 { position: relative; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
p { -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0rem; -webkit-margin-after: 0rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: bold; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-radius: 4px; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; margin: 4px 0px 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
pre { white-space: pre-wrap; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences .CodeMirror.CodeMirror-wrap { top: -1.6em; margin-bottom: -1.6em; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; padding-top: 1em; padding-bottom: 1em; }
.footnotes + .footnotes { margin-top: -1em; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: transparent; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: normal; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li p, li .mathjax-block { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; }
@media print {
  html, body { height: 100%; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
  p { orphans: 4; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0mm; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 2.86rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
.mathjax-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: none; box-shadow: none; }
.task-list { list-style-type: none; }
.task-list-item { position: relative; padding-left: 1em; }
.task-list-item input { position: absolute; top: 0px; left: 0px; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc::after, .md-toc-content::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: bold; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
.md-tag { opacity: 0.5; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: monospace; }
code { text-align: left; }
h1 .md-tag, h2 .md-tag, h3 .md-tag, h4 .md-tag, h5 .md-tag, h6 .md-tag { font-weight: initial; opacity: 0.35; }
a.md-print-anchor { border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: none !important; background: transparent !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0em; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: normal; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }


@font-face { font-family: "Open Sans"; font-style: normal; font-weight: normal; src: local("Open Sans Regular"), url("./github/400.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: normal; src: local("Open Sans Italic"), url("./github/400i.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: bold; src: local("Open Sans Bold"), url("./github/700.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: bold; src: local("Open Sans Bold Italic"), url("./github/700i.woff") format("woff"); }
html { font-size: 16px; }
body { font-family: "Open Sans", "Clear Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; color: rgb(51, 51, 51); line-height: 1.6; }
#write { max-width: 860px; margin: 0px auto; padding: 20px 30px 100px; }
#write > ul:first-child, #write > ol:first-child { margin-top: 30px; }
body > :first-child { margin-top: 0px !important; }
body > :last-child { margin-bottom: 0px !important; }
a { color: rgb(65, 131, 196); }
h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; }
h1 tt, h1 code { font-size: inherit; }
h2 tt, h2 code { font-size: inherit; }
h3 tt, h3 code { font-size: inherit; }
h4 tt, h4 code { font-size: inherit; }
h5 tt, h5 code { font-size: inherit; }
h6 tt, h6 code { font-size: inherit; }
h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
h3 { font-size: 1.5em; line-height: 1.43; }
h4 { font-size: 1.25em; }
h5 { font-size: 1em; }
h6 { font-size: 1em; color: rgb(119, 119, 119); }
p, blockquote, ul, ol, dl, table { margin: 0.8em 0px; }
li > ol, li > ul { margin: 0px; }
hr { height: 4px; padding: 0px; margin: 16px 0px; background-color: rgb(231, 231, 231); border-width: 0px 0px 1px; border-style: none none solid; border-top-color: initial; border-right-color: initial; border-left-color: initial; border-image: initial; overflow: hidden; box-sizing: content-box; border-bottom-color: rgb(221, 221, 221); }
body > h2:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child + h2 { margin-top: 0px; padding-top: 0px; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child { margin-top: 0px; padding-top: 0px; }
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 { margin-top: 0px; padding-top: 0px; }
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p { margin-top: 0px; }
li p.first { display: inline-block; }
ul, ol { padding-left: 30px; }
ul:first-child, ol:first-child { margin-top: 0px; }
ul:last-child, ol:last-child { margin-bottom: 0px; }
blockquote { border-left: 4px solid rgb(221, 221, 221); padding: 0px 15px; color: rgb(119, 119, 119); }
blockquote blockquote { padding-right: 0px; }
table { padding: 0px; word-break: initial; }
table tr { border-top: 1px solid rgb(204, 204, 204); background-color: white; margin: 0px; padding: 0px; }
table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
table tr th { font-weight: bold; border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr td { border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr th:first-child, table tr td:first-child { margin-top: 0px; }
table tr th:last-child, table tr td:last-child { margin-bottom: 0px; }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); }
.md-fences, code, tt { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; }
.md-fences { margin-bottom: 15px; margin-top: 15px; padding: 8px 1em 6px; }
.task-list { padding-left: 0px; }
.task-list-item { padding-left: 32px; }
.task-list-item input { top: 3px; left: 8px; }
@media screen and (min-width: 914px) {
}
@media print {
  html { font-size: 13px; }
  table, pre { break-inside: avoid; }
  pre { word-wrap: break-word; }
}
.md-fences { background-color: rgb(248, 248, 248); }
#write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: rgb(247, 247, 247); border: 0px; border-radius: 3px; color: rgb(119, 119, 119); margin-top: 0px !important; }
.mathjax-block > .code-tooltip { bottom: 0.375rem; }
#write > h3.md-focus::before { left: -1.5625rem; top: 0.375rem; }
#write > h4.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h5.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h6.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
.md-image > .md-meta { border: 1px solid rgb(221, 221, 221); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; color: inherit; }
.md-tag { color: inherit; }
.md-toc { margin-top: 20px; padding-bottom: 20px; }
#typora-quick-open { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); }
#typora-quick-open-item { background-color: rgb(250, 250, 250); border-color: rgb(254, 254, 254) rgb(229, 229, 229) rgb(229, 229, 229) rgb(238, 238, 238); border-style: solid; border-width: 1px; }
#md-notification::before { top: 10px; }
.on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.117647); }
header, .context-menu, .megamenu-content, footer { font-family: "Segoe UI", Arial, sans-serif; }






</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-node'><h1><a name='header-n0' class='md-header-anchor '></a>机器学习中特征工程在中国股票市场的应用——基于沪深300指数日度数据</h1><p></p><blockquote><p>The algorithms we used are very standard for Kagglers. […] We spent most of our efforts in feature engineering. [...] We were also very careful to discard features likely to expose us to the risk of over-fitting our model.</p></blockquote><p> — Xavier Conort, &quot;Q&amp;A with Xavier Conort&quot;（Kaggle首席数据科学家）</p><p></p><blockquote><p>“Coming up with features is difficult, time-consuming, requires expert knowledge. &quot;Applied machine learning&quot; is basically feature engineering.”</p></blockquote><p> —Andrew Ng, （吴恩达，斯坦福教授，Coursera中著名的机器学习课程主讲人，前百度人工智能实验室负责人）</p><p></p><h1><a name='header-n18' class='md-header-anchor '></a>简介：</h1><p>在机器学习中，运用特征工程对于预测结果的准确性至关重要。本文利用Wind资讯金融终端平台获取的沪深300指数日度数据（10年以上，约3000个），通过对原始数据的提取，总共构建67个特征变量。本文运用特征工程主要目的是利用第t-1个交易日的特征维度信息来尽可能提高第t个交易日走势判断的准确率。对67个特征变量经过特征选择后， 形成集成特征打分器，选中排名前3个特征变量作为K-平均聚类方法的输入值。对聚类的结果进行收益率和波动率的统计，证明得到的聚类存在两个明显不同的收益率分布，并基于此提出一个基准择时策略，该策略拥有17%的平均年化收益率，说明了运用特征工程的有效性。</p><p></p><h2><a name='header-n23' class='md-header-anchor '></a>1.背景知识</h2><h3><a name='header-n24' class='md-header-anchor '></a>1.1 特征工程（Feature Engineering）</h3><p>简单来说，特征工程是将原始数据转化为特征，并运用这些特征来提升预测目标变量的准确性。</p><p>在日常的数据分析中，我们会把数据整理成（观测值，特征维度）的两维数据列表的形式。例如，对于一个人数为50的班级，我们可以从 1 到 50， 对学生进行编号，并选定姓名，性别，身高，体重，成绩 5 个维度作为分析的特征变量。此时我们的得到的就是一个 50 乘 5 的数据框（dataframe）。</p><h5><a name='header-n29' class='md-header-anchor '></a>1.1.1 特征构建（Feature  Construction）</h5><p>一般来说在目标问题的特定领域分析上，对原特征维度进行组合变换产生新特征维度，就是指特征构建，加入这些新特征会增强模型的解释力（explanatory power）。</p><p>例如，如果我们感兴趣的问题是以上班级学生的健康状况，我们可以通过身高和体重计算学生的的BMI（body mass index）值：</p><p><strong>BMI（体质指数）=体重（kg）÷ 身高²（m）</strong></p><p>通常认为 BMI 在18.5~25之间为合理体重。在这里，BMI 值就是对身高和体重两个维度的组合变换。这种对原特征维度进行变换，来寻找新特征维度的做法，便是特征构建。</p><h5><a name='header-n38' class='md-header-anchor '></a>1.1.2 特征选择（Feature Subset Selection）</h5><p>当获得大体量的特征数据集后，由于变量特征的庞大必然存在冗余（redundant）和噪声不相关（irrelevant），需要我们选择有意义的特征输入机器学习的算法和模型进行训练，这就是特征选择。</p><p>一般一个完整的特征选择过程包括四个步骤,如下图所示：</p><p><img src='p/feature_selection.png' alt='' /></p><p><strong>1.子集搜索（subset generation/search）</strong>：按照一定的搜索策略产生候选特征子集；</p><p><strong>2.子集评估（subset evaluation）</strong>：通过某个评价函数评估特征子集的优劣；</p><p><strong>3.停止条件（stopping criterion）</strong>：决定特征选择算法什么时候停止；</p><p><strong>4.子集验证（subset  validity）</strong>：用于验证最终所选的特征子集的有效性。</p><p></p><p>通常选择特征变量从两个方面考虑：</p><ul><li><p><strong>特征是否发散</strong>：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上没有差异，基本是一个均匀分布。那么该特征对于目标变量的区分并没有什么用。</p></li><li><p><strong>特征与目标的相关性</strong>：这个比较容易理解，与目标相关性高的特征，应当优选选择。</p><p>​</p></li></ul><p>根据特征选择的具体过程又可分为3种:</p><ul><li><p><strong>过滤法（Filter）</strong>：按照发散性或相关性对各个特征进行评估，设定阈值或待选特征个数。过滤式特征选择的评价标准从数据集本身的内在性质获得，与特定的学习算法无关，因此具有较好的通用性。</p></li><li><p><strong>封装法（Wrapper）</strong>：根据目标函数，每次选择若干特征，或者排除若干特征，即需要经过多次子集评估后到达目标函数的停止条件后结束。封装法利用学习算法的性能来评价特征子集的优劣，由于是专门训练得到模型通用性不强，且算法计算复杂度高，执行时间长。</p></li><li><p><strong>嵌入法（Embedded）</strong>：特征选择算法本身作为组成部分嵌入到学习算法里。通过递归自适应调节各个特征变量的系数直至收敛。与wrapper相比最大区别就是特征子集不需要按方法搜索，靠算法自动选择。</p><p>​</p></li></ul><h5><a name='header-n80' class='md-header-anchor '></a>1.1.3 集成学习方法（ensemble learning method）：</h5><p>通过特征工程产生了大量的特征变量，数据集中包含噪音，共线性，非线性相关等问题。通过集成学习方法，组合特征选择的多个模型，以获得更好的预测效果，使集成的模型具有更强的泛化能力。可以尽量减少数据和单一特征选择方法引起的问题，并改善特征选择的效果。
<img src='p/ensemble_learning.jpg' alt='' /></p><h5><a name='header-n84' class='md-header-anchor '></a>1.1.4 特征抽取（feature extraction）</h5><p>特征抽取也称作特征降维，与特征选择只是对特征进行筛选不同，特征提取是指利用已有的特征计算出一个抽象程度更高的特征集，从原有的较多维度特征数据降低为较低维度特征数据。以此估计的模型，往往有比原来更好的预测效果。</p><p></p><h3><a name='header-n89' class='md-header-anchor '></a>1.2股票市场（Stock Market）</h3><h5><a name='header-n90' class='md-header-anchor '></a>1.2.1 股票指数</h5><p>我们经常能听到股市怎么怎么好，大盘又涨了XX点，其实说的对象就是股票市场中的指数，在国内经常提到的是上证指数（000001）和深证成指（399001），它们分别反映了上海证券交易所和深圳证券交易所上市股票的整体走势。</p><p></p><h5><a name='header-n95' class='md-header-anchor '></a>1.2.2 沪深300指数</h5><p>本文主要的研究对象是沪深300指数（000300），是在上海和深圳证券交易所中选取300只A股作为样本编制而成的成份股指数。</p><p>沪深300指数主要优势是反映沪深两个市场整体走势的“晴雨表”。指数样本选自沪深两个证券市场，覆盖了沪深市场六成左右的市值。成份股为市场中市场代表性好，流动性高，交易活跃，规模大的主流投资股票，能够反映市场主流投资的收益情况。</p><p></p><h2><a name='header-n102' class='md-header-anchor '></a>2.数据初步探索性分析</h2><h3><a name='header-n103' class='md-header-anchor '></a>2.1数据获取</h3><p>本文所研究的对象是沪深300指数，原始数据是通过Wind资讯金融数据终端的行情序列导出所得，原始数据如下表所示：</p><p>总共3006行*9列数据，时间跨度接近12年（每年大概250个交易日），以2014年12月31日的收盘价为基准（1000点），主要数据包括开盘价，收盘价，最高价，最低价，成交量（股），成交金额（元）。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure">AخA</div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">pandas</span> <span class="cm-keyword">as</span> <span class="cm-variable">pd</span></span></pre></div></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 23px;"></div></div></div></pre><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#read the excel table</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">hs300</span> = <span class="cm-variable">pd</span>.<span class="cm-property">read_excel</span>(<span class="cm-string">'沪深300.xlsx'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">hs300</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 68px;"></div></div></div></pre><table><thead><tr><th style='text-align:left;' ></th><th style='text-align:left;' >代码</th><th style='text-align:left;' >简称</th><th style='text-align:left;' >日期</th><th style='text-align:left;' >开盘价</th><th style='text-align:left;' >最高价</th><th style='text-align:left;' >最低价</th><th style='text-align:left;' >收盘价</th><th style='text-align:left;' >成交量(股)</th><th style='text-align:left;' >成交金额(元)</th></tr></thead><tbody><tr><td style='text-align:left;' >0</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >12/31/2004</td><td style='text-align:left;' >--</td><td style='text-align:left;' >--</td><td style='text-align:left;' >--</td><td style='text-align:left;' >1000</td><td style='text-align:left;' >--</td><td style='text-align:left;' >--</td></tr><tr><td style='text-align:left;' >1</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >1/4/2005</td><td style='text-align:left;' >994.769</td><td style='text-align:left;' >994.769</td><td style='text-align:left;' >980.658</td><td style='text-align:left;' >982.794</td><td style='text-align:left;' >741286894</td><td style='text-align:left;' >4431977418</td></tr><tr><td style='text-align:left;' >2</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >1/5/2005</td><td style='text-align:left;' >981.577</td><td style='text-align:left;' >997.323</td><td style='text-align:left;' >979.877</td><td style='text-align:left;' >992.564</td><td style='text-align:left;' >711910898</td><td style='text-align:left;' >4529208214</td></tr><tr><td style='text-align:left;' >3</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >1/6/2005</td><td style='text-align:left;' >993.331</td><td style='text-align:left;' >993.788</td><td style='text-align:left;' >980.33</td><td style='text-align:left;' >983.174</td><td style='text-align:left;' >628802905</td><td style='text-align:left;' >3921015420</td></tr><tr><td style='text-align:left;' >4</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >1/7/2005</td><td style='text-align:left;' >983.045</td><td style='text-align:left;' >995.711</td><td style='text-align:left;' >979.812</td><td style='text-align:left;' >983.958</td><td style='text-align:left;' >729869409</td><td style='text-align:left;' >4737469399</td></tr><tr><td style='text-align:left;' >5</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >1/10/2005</td><td style='text-align:left;' >983.76</td><td style='text-align:left;' >993.959</td><td style='text-align:left;' >979.789</td><td style='text-align:left;' >993.879</td><td style='text-align:left;' >579169799</td><td style='text-align:left;' >3762932890</td></tr><tr><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td><td style='text-align:left;' >...</td></tr><tr><td style='text-align:left;' >3001</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >5/12/2017</td><td style='text-align:left;' >3350.94</td><td style='text-align:left;' >3387.27</td><td style='text-align:left;' >3349.17</td><td style='text-align:left;' >3385.3787</td><td style='text-align:left;' >9338646600</td><td style='text-align:left;' >97522124500</td></tr><tr><td style='text-align:left;' >3002</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >5/15/2017</td><td style='text-align:left;' >3391.59</td><td style='text-align:left;' >3406.58</td><td style='text-align:left;' >3391.59</td><td style='text-align:left;' >3399.1937</td><td style='text-align:left;' >8297761100</td><td style='text-align:left;' >92183332800</td></tr><tr><td style='text-align:left;' >3003</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >5/16/2017</td><td style='text-align:left;' >3390.93</td><td style='text-align:left;' >3428.85</td><td style='text-align:left;' >3373.55</td><td style='text-align:left;' >3428.6491</td><td style='text-align:left;' >10524241600</td><td style='text-align:left;' >1.12814E+11</td></tr><tr><td style='text-align:left;' >3004</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >5/17/2017</td><td style='text-align:left;' >3423.19</td><td style='text-align:left;' >3433.97</td><td style='text-align:left;' >3408.15</td><td style='text-align:left;' >3409.9656</td><td style='text-align:left;' >9973683700</td><td style='text-align:left;' >1.10553E+11</td></tr><tr><td style='text-align:left;' >3005</td><td style='text-align:left;' >399300.SZ</td><td style='text-align:left;' >沪深300</td><td style='text-align:left;' >5/18/2017</td><td style='text-align:left;' >3387.67</td><td style='text-align:left;' >3409.93</td><td style='text-align:left;' >3383.93</td><td style='text-align:left;' >3398.1127</td><td style='text-align:left;' >8575958900</td><td style='text-align:left;' >8809116600</td></tr></tbody></table><p>3006 rows × 9 columns</p><p></p><h3><a name='header-n258' class='md-header-anchor '></a>2.2 数据预处理</h3><h4><a name='header-n259' class='md-header-anchor '></a>2.2.1 生成对数收益率</h4><p>原本这一节的内容应放在下一章的特征构建中，但是收益率是股票市场量化研究的重要目标特征变量对它进行探索性分析非常必要，所以在这一章来讲。</p><p><strong>对数收益率公式</strong>：</p><p>​                              <strong>Rt=ln(Pt/Pt-1）</strong></p><p><strong>对数收益率（log return）</strong>相比<strong>普通百分比收益率（simple return）</strong>的好处：</p><ul><li><p><strong>对数收益率的可加性</strong>：用r1表示t1到t2的收益率，r2同理。如果是对数收益率，则r1+r2即可表示t1到t3的收益率，而普通百分比收益率并不能这样表示。</p></li><li><p><strong>对数收益率更平稳</strong>：取对数可以让数据更加平稳，但是不会改变数据间的相关关系。同时削弱了数据的异方差和共线性，利于模型估计。</p><p>​</p></li></ul><h4><a name='header-n277' class='md-header-anchor '></a>2.2.2 数据清洗</h4><p>该步骤主要用于清洗异常样本和缺失值。在本文的实际应用中由于获取的沪深300指数日数据都是标准的且没有缺失值（除第一行外），所以基本不需要对原始数据进行处理，删去第一行的数据，最终获得基础数据为<strong>3005行 ×10列</strong>的数据集。</p><p></p><h3><a name='header-n282' class='md-header-anchor '></a>2.3 收益率数据探索性分析</h3><p>本节对沪深300指数的涨跌情况和对数收益率进行了描述性统计，并作出相关的统计图以更好地展示和说明该数据的情况。</p><h4><a name='header-n285' class='md-header-anchor '></a>2.3.1 指数涨跌统计和饼图</h4><p>官方的涨跌概念，是认为第t个交易日的指数收盘价大于第t-1个交易日的收盘价，就可说明指数第t个交易日上涨（这可能与普通大众认为的第t个交易日的指数收盘价大于第t个交易日的开盘价就为上涨不同）。</p><p>最终的统计结果如下图所示：总体来看，沪深300指数从2005-01-04到2017-05-18时段内，上涨天数（1614天）多于下跌天数（1391天）。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#statistics for daily  fluctuation</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">up_and_down</span> = <span class="cm-variable">hs300</span>[<span class="cm-string">'对数收益率'</span>] <span class="cm-operator">&gt;</span> <span class="cm-number">0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">up_and_down_statistic</span> = <span class="cm-variable">up_and_down</span>.<span class="cm-property">value_counts</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#pie plot</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">label</span> = [<span class="cm-string">'up'</span>,<span class="cm-string">'down'</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">pie</span>(<span class="cm-variable">up_and_down_statistic</span>, <span class="cm-variable">labels</span>=<span class="cm-variable">label</span>, <span class="cm-variable">autopct</span>=<span class="cm-string">'%1.2f%%'</span> )</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 159px;"></div></div></div></pre><p></p><p>   <img src='p/pie.png' alt='' /></p><h4><a name='header-n295' class='md-header-anchor '></a>2.3.2 对数收益率描述性统计和箱形图</h4><p>对数收益率的描述性统计结果和箱形图如下所示，相关代码也已列出。我们把对数收益率分成三组，一组是全部数据，一组是上涨的组别，最后一组是下跌的组别，把统计表格与箱形图结合来看：</p><p>总体的平均收益率大于0且非常接近于0，然而又发现下跌的平均收益率绝对值大于上涨的平均收益率值，这也间接说明上涨的天数大于下跌的天数。</p><p>同时对数收益率整体大于0，上涨的对数收益率与下跌的对数收益率的箱形图基本一致，平均收益率上涨的稍低。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#descriptive statistics and box plot</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ln_yield</span>  = <span class="cm-variable">pd</span>.<span class="cm-property">Series</span>(<span class="cm-variable">return_rate</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">up_ln_yield</span> = <span class="cm-variable">ln_yield</span>[<span class="cm-variable">ln_yield</span> <span class="cm-operator">&gt;</span> <span class="cm-number">0</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">down_ln_yield</span> = <span class="cm-variable">ln_yield</span>[<span class="cm-variable">ln_yield</span> <span class="cm-operator">&lt;</span> <span class="cm-number">0</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s1</span> = <span class="cm-variable">ln_yield</span>.<span class="cm-property">describe</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s2</span> = <span class="cm-variable">up_ln_yield</span>.<span class="cm-property">describe</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s3</span> = <span class="cm-variable">down_ln_yield</span>.<span class="cm-property">describe</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">pd</span>.<span class="cm-property">concat</span>({<span class="cm-string">'all'</span>:<span class="cm-variable">s1</span>, <span class="cm-string">'up'</span>:<span class="cm-variable">s2</span>, <span class="cm-string">'down'</span>:<span class="cm-variable">s3</span>}, <span class="cm-variable">axis</span>=<span class="cm-number">1</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 181px;"></div></div></div></pre><table><thead><tr><th></th><th>all</th><th>down</th><th>up</th></tr></thead><tbody><tr><td>count</td><td>3005</td><td>1391</td><td>1614</td></tr><tr><td>mean</td><td>0.000407</td><td>-0.013216</td><td>0.0121480</td></tr><tr><td>std</td><td>0.018211</td><td>0.014478</td><td>0.01178978</td></tr><tr><td>min</td><td>-0.096949</td><td>-0.096949</td><td>0.000000355</td></tr><tr><td>25%</td><td>-0.007703</td><td>-0.017409</td><td>0.003421797</td></tr><tr><td>50%</td><td>0.000969</td><td>-0.008632</td><td>0.008487688</td></tr><tr><td>75%</td><td>0.009449</td><td>-0.003555</td><td>0.01742251</td></tr><tr><td>max</td><td>0.089310</td><td>-0.000006</td><td>0.08931021</td></tr></tbody></table><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#box plot</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s4</span> = <span class="cm-variable">pd</span>.<span class="cm-property">DataFrame</span>([<span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-variable">ln_yield</span>), <span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-variable">up_ln_yield</span>), <span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-operator">-</span><span class="cm-variable">down_ln_yield</span>)]).<span class="cm-property">T</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s4</span>.<span class="cm-property">columns</span> = [<span class="cm-string">'all'</span>, <span class="cm-string">'up'</span>, <span class="cm-string">'down'</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">s4</span>.<span class="cm-property">plot</span>(<span class="cm-variable">kind</span>=<span class="cm-string">'box'</span>, <span class="cm-variable">figsize</span>=(<span class="cm-number">15</span>,<span class="cm-number">10</span>), <span class="cm-variable">title</span> = <span class="cm-string">'box plot of daily log return(the down data is absolute value)'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">ylim</span>(<span class="cm-operator">-</span><span class="cm-number">0.04</span>, <span class="cm-number">0.04</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 136px;"></div></div></div></pre><p><img src='p/box.png' alt='' /></p><p></p><h4><a name='header-n354' class='md-header-anchor '></a>2.3.3 对数收益率的时间序列变化图</h4><p>如下图所示：可以明显看到对数收益率的变化在两段时期波动剧烈（<em>2007年，2015年，都是大牛市的开端并且达到顶峰后迅速下跌，波动率异常的大</em>）。</p><p>再看最近时期的波动率变化，<strong>2016年开始收益率变化程度降低，基本上涨跌幅控制在1%范围内，也正说明了股市在证监会的强势监管下逐步趋稳</strong>。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#Log yield Variation in the past </span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ln_yield</span>.<span class="cm-property">plot</span>(<span class="cm-variable">kind</span>=<span class="cm-string">'line'</span>, <span class="cm-variable">style</span>=<span class="cm-string">'k--'</span>, <span class="cm-variable">figsize</span>=(<span class="cm-number">15</span>, <span class="cm-number">10</span>), <span class="cm-variable">title</span>=<span class="cm-string">'Daily Yield Changes Over Time Series'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 68px;"></div></div></div></pre><p><img src='p/log_yield_changes.png' alt='' /></p><p></p><h4><a name='header-n364' class='md-header-anchor '></a>2.3.4 条形图和密度曲线</h4><p>如下图所示：通过条形图和密度曲线的展示，对数收益率基本符合正态分布，但仔细看会发现均值稍微大于0，主要是因为上涨的天数更多。尤其是收益率在[-0.05,0.05]内上涨大于下跌。</p><p>而在收益率绝对值大于0.05 的范围内，下跌的会明显多于上涨的，可以看到小于-0.05收益率这块曲线有一个明显的凸起，而对应上涨部分则是正常曲线。这说明了<strong>微涨天数大于微跌天数，而暴跌天数大于暴涨天数，表达了股票市场更倾向于慢慢持久上涨，而下跌时则会短期内迅速下跌</strong>。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#Frequency distribution of up and down</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ln_yield</span>.<span class="cm-property">hist</span>(<span class="cm-variable">bins</span>=<span class="cm-number">100</span>, <span class="cm-variable">alpha</span>=<span class="cm-number">0.3</span>, <span class="cm-variable">color</span>=<span class="cm-string">'g'</span>, <span class="cm-variable">normed</span>=<span class="cm-builtin">True</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#Kernel Density Estimate</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ln_yield</span>.<span class="cm-property">plot</span>(<span class="cm-variable">kind</span>=<span class="cm-string">'kde'</span>, <span class="cm-variable">xlim</span>=[<span class="cm-operator">-</span><span class="cm-number">0.1</span>, <span class="cm-number">0.1</span>], <span class="cm-variable">style</span>=<span class="cm-string">'r'</span>, <span class="cm-variable">grid</span>=<span class="cm-builtin">True</span>, </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">figsize</span>=(<span class="cm-number">15</span>, <span class="cm-number">10</span>), <span class="cm-variable">title</span>=<span class="cm-string">'Frequency Distribution Of Up And Down &amp; Kernel Density Estimate Curve'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 136px;"></div></div></div></pre><p><img src='p/bar.png' alt='' /></p><p></p><h2><a name='header-n374' class='md-header-anchor '></a>3.特征变量构建和可视化分析</h2><p>本章讲述特征变量的构建，即如何通过原有的特征数据组合计算得到新的特征变量。本文中特征变量的获取方式，一部分纯依靠数据挖掘的方式获得，一部分是为了解决目标问题而依托专业和常识性知识所获得，也有一部分是结合两者特点所获得的特征变量，最终我们把得到的所有特征变量分为三种：<strong>基础变量</strong>，<strong>经典技术指标变量</strong>，<strong>阿尔法变量</strong>。</p><p>得到特征变量后，我们通过一系列条形图、箱形图、密度曲线，相关系数热力图等可视化操作分析方式呈现各个特征变量的分布。初步探讨了特征变量的分布以及与目标变量的相关性，为后续进行的特征选择提供参考。</p><p>然后我们汇总合并了每个特征数据，并使得它们的时间戳保持一致。最后对每一列特征变量分别进行标准化处理，使得模型估计的系数保持在一定范围内。</p><p><em>由于篇幅有限，每个特征变量的具体公式和概念不在这章里一一列举，具体见附录。</em></p><h3><a name='header-n383' class='md-header-anchor '></a>3.1  <strong>10个基础变量</strong>：</h3><p>开盘价（open），收盘价（close)，日内最高价(high)，日内最低价（low），成交量（volume），成交总额（amount），成交均价（price），日内涨跌幅（daily_gain），日内区间（daily_region），日内开盘涨幅（daily_opengain）。</p><h4><a name='header-n386' class='md-header-anchor '></a>3.1.1 基础变量描述性统计和箱形图</h4><p>如下表和图所示 我们一共得到10个基础变量，其中每个变量长度都统一控制为2047个（与所有变量中的最小值保持一致），时间戳全部对应为2005-04-05——2017-05-18，箱形图中有个别几个区间较小，是因为存在较大的异常值压缩了正常值的显示空间。</p><table><thead><tr><th></th><th>open</th><th>close</th><th>high</th><th>low</th><th>volume</th><th>amount</th></tr></thead><tbody><tr><td>count</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td></tr><tr><td>mean</td><td>2788.831119</td><td>2791.799181</td><td>2819.455457</td><td>2757.694252</td><td>8.557676e+09</td><td>1.009196e+11</td></tr><tr><td>std</td><td>1006.997616</td><td>1006.593634</td><td>1019.906328</td><td>989.646104</td><td>8.664803e+09</td><td>1.178769e+11</td></tr><tr><td>min</td><td>816.546000</td><td>818.033000</td><td>823.860000</td><td>807.784000</td><td>5.962465e+08</td><td>2.901827e+09</td></tr><tr><td>25%</td><td>2262.310000</td><td>2265.589500</td><td>2290.346000</td><td>2236.145000</td><td>3.928517e+09</td><td>4.227502e+10</td></tr><tr><td>50%</td><td>2753.688000</td><td>2758.495000</td><td>2784.916000</td><td>2725.362000</td><td>6.246805e+09</td><td>7.062610e+10</td></tr><tr><td>75%</td><td>3349.027000</td><td>3354.487500</td><td>3377.174450</td><td>3327.248500</td><td>9.408543e+09</td><td>1.131326e+11</td></tr><tr><td>max</td><td>5862.378000</td><td>5877.202000</td><td>5891.723000</td><td>5815.609000</td><td>6.864391e+10</td><td>9.494980e+11</td></tr></tbody></table><table><thead><tr><th></th><th>price</th><th>daily_gain</th><th>daily_region</th><th>daily_opengain</th></tr></thead><tbody><tr><td>count</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td></tr><tr><td>mean</td><td>10.969191</td><td>1.000159</td><td>1.002695</td><td>0.999901</td></tr><tr><td>std</td><td>3.520024</td><td>0.002128</td><td>0.001757</td><td>0.000983</td></tr><tr><td>min</td><td>3.943499</td><td>0.987267</td><td>1.000437</td><td>0.991165</td></tr><tr><td>25%</td><td>9.028242</td><td>0.999178</td><td>1.001526</td><td>0.999634</td></tr><tr><td>50%</td><td>10.650831</td><td>1.000153</td><td>1.002186</td><td>0.999962</td></tr><tr><td>75%</td><td>12.921256</td><td>1.001246</td><td>1.003329</td><td>1.000250</td></tr><tr><td>max</td><td>23.517610</td><td>1.010637</td><td>1.013976</td><td>1.011364</td></tr></tbody></table><p><img src='p/box_3_1.png' alt='' /></p><p></p><h4><a name='header-n521' class='md-header-anchor '></a>3.1.2 基础变量的条形图和密度曲线</h4><p>特征变量基本都呈现正态分布，大部分数值集中在一个区间。有一个有趣的现象，基础变量中的四个价格，open，close，high，low 在1000-2000点之间呈现一个最低点，这可能说明<strong>沪深300指数较快的跨越了这个区间，并且以后下跌也很难跌到这个区间里</strong>。
<img src='p/bar_3_1.png' alt='' /></p><p><img src='p/density_3_1.png' alt='' /></p><p></p><h4><a name='header-n529' class='md-header-anchor '></a>3.1.3 基础变量的相关系数表和热力图</h4><p>以下就是10个基础变量加上目标变量（第二天的对数收益率）的相关系数表和热力图。按绝对值大小来比较，之前提到的四个价格的基础变量加上price与对数收益率的相关系数的绝对值在  0.08-0.09 范围，属于较高的水平，其余的差一些。但是这五个基础变量，本身也存在较为严重的共线性。</p><table><thead><tr><th></th><th>open</th><th>close</th><th>high</th><th>low</th><th>volume</th><th>amount</th><th>...</th><th>ret</th></tr></thead><tbody><tr><td>open</td><td>1.000000</td><td>0.998581</td><td>0.999499</td><td>0.999237</td><td>0.443139</td><td>0.545025</td><td>...</td><td>-0.082633</td></tr><tr><td>close</td><td>0.998581</td><td>1.000000</td><td>0.999281</td><td>0.999307</td><td>0.445490</td><td>0.546691</td><td>...</td><td>-0.079924</td></tr><tr><td>high</td><td>0.999499</td><td>0.999281</td><td>1.000000</td><td>0.999014</td><td>0.448638</td><td>0.549896</td><td>...</td><td>-0.081173</td></tr><tr><td>low</td><td>0.999237</td><td>0.999307</td><td>0.999014</td><td>1.000000</td><td>0.439285</td><td>0.540714</td><td>...</td><td>-0.081665</td></tr><tr><td>volume</td><td>0.443139</td><td>0.445490</td><td>0.448638</td><td>0.439285</td><td>1.000000</td><td>0.974043</td><td>...</td><td>-0.008074</td></tr><tr><td>amount</td><td>0.545025</td><td>0.546691</td><td>0.549896</td><td>0.540714</td><td>0.974043</td><td>1.000000</td><td>...</td><td>-0.025198</td></tr><tr><td>price</td><td>0.937753</td><td>0.937114</td><td>0.938498</td><td>0.936692</td><td>0.231188</td><td>0.360854</td><td>...</td><td>-0.090391</td></tr><tr><td>daily_gain</td><td>-0.051597</td><td>-0.002042</td><td>-0.029678</td><td>-0.026413</td><td>0.038838</td><td>0.021587</td><td>...</td><td>0.052516</td></tr><tr><td>daily_region</td><td>0.113776</td><td>0.109764</td><td>0.130415</td><td>0.088784</td><td>0.239805</td><td>0.235414</td><td>...</td><td>0.001494</td></tr><tr><td>daily_opengain</td><td>0.018735</td><td>0.016985</td><td>0.013285</td><td>0.018844</td><td>0.033436</td><td>0.040383</td><td>...</td><td>-0.024746</td></tr><tr><td>ret</td><td>-0.082633</td><td>-0.079924</td><td>-0.081173</td><td>-0.081665</td><td>-0.008074</td><td>-0.025198</td><td>...</td><td>1.000000</td></tr></tbody></table><p><img src='p/corr_3_1.png' alt='' /></p><p></p><h3><a name='header-n657' class='md-header-anchor '></a>3.2  <strong>衍生经典技术指标变量</strong>(常识性的股票市场经典技术指标)：</h3><p>我们把技术指标变量细分为以下5类：（<em>具体公式和概念详见附录</em>）</p><p><strong>趋势指标</strong>：MACD,AMA,TRIX,VHF,RVI</p><p><strong>震荡指标</strong>：KDJ,BIAS,ForceIndex</p><p><strong>超买超卖指标</strong>：VR,DPO,NVI,PVI,ROC</p><p><strong>能量指标</strong>：OBV,PSY</p><p><strong>动量指标</strong>：MTM<em>6,MTM</em>12,CMO</p><h4><a name='header-n670' class='md-header-anchor '></a>3.2.1 技术指标变量描述性统计和箱形图</h4><p>一共20个技术指标变量，基本都是在正常的取值范围内，由于无量纲，不同变量之间在进行标准化之前无法相互比较，个别变量如ForceIndex，VR，CMO变量中存在个别较大的极端值引起箱形图的长度较窄。</p><table><thead><tr><th></th><th>MACD</th><th>AMA</th><th>TRIX</th><th>VHF</th><th>...</th><th>MTM_6</th><th>MTM_12</th><th>CMO</th></tr></thead><tbody><tr><td>count</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td><td>...</td><td>2947</td><td>2947</td><td>2947</td></tr><tr><td>mean</td><td>-0.017848</td><td>16.591102</td><td>0.037154</td><td>0.414883</td><td>...</td><td>4.968615</td><td>9.867754</td><td>4.581011</td></tr><tr><td>std</td><td>41.232976</td><td>222.665938</td><td>1.071344</td><td>0.122342</td><td>...</td><td>150.479777</td><td>217.008249</td><td>6.696297</td></tr><tr><td>min</td><td>-244.320432</td><td>-714.074876</td><td>-6.913573</td><td>0.193536</td><td>...</td><td>-1034.945</td><td>-1178.904</td><td>-17.352639</td></tr><tr><td>25%</td><td>-15.243229</td><td>-77.372235</td><td>-0.474844</td><td>0.323869</td><td>...</td><td>-53.5505</td><td>-78.649</td><td>1.968651</td></tr><tr><td>50%</td><td>2.04296</td><td>16.422578</td><td>0.085551</td><td>0.394415</td><td>...</td><td>10.187</td><td>17.4208</td><td>2.611093</td></tr><tr><td>75%</td><td>19.480999</td><td>108.275399</td><td>0.647835</td><td>0.48071</td><td>...</td><td>75.4275</td><td>110.7555</td><td>4.348366</td></tr><tr><td>max</td><td>185.662115</td><td>778.41741</td><td>5.501324</td><td>0.899901</td><td>...</td><td>662.842</td><td>896.987</td><td>30.332605</td></tr></tbody></table><p>8 rows × 20 columns</p><p></p><p><img src='p/box_3_2.png' alt='' /></p><p></p><h4><a name='header-n772' class='md-header-anchor '></a>3.2.2 技术指标变量的条形图和密度曲线</h4><p>基本呈现的都是正态分布，有个别变量的数值会更加集中在小的区间内。
<img src='p/bar_3_2.png' alt='' /></p><p><img src='p/density_3_2.png' alt='' /></p><p></p><h4><a name='header-n780' class='md-header-anchor '></a>3.2.3 技术指标变量的相关系数表和热力图</h4><p>20个指标与第二天对数收益率的相关系数绝对值多集中在（0.03-0.05），比之前的五个价格变量低一些。而且从热力图中可以看出20个不同指标间存在明显的共线性。</p><table><thead><tr><th></th><th>MACD</th><th>AMA</th><th>TRIX</th><th>VHF</th><th>...</th><th>MTM_12</th><th>CMO</th><th>ret</th></tr></thead><tbody><tr><td>MACD</td><td>1</td><td>-0.200796</td><td>0.421941</td><td>0.08263</td><td>...</td><td>0.788774</td><td>-0.006458</td><td>0.01672</td></tr><tr><td>AMA</td><td>-0.200796</td><td>1</td><td>0.089956</td><td>0.229946</td><td>...</td><td>0.357106</td><td>0.3441</td><td>0.041914</td></tr><tr><td>TRIX</td><td>0.421941</td><td>0.089956</td><td>1</td><td>0.117086</td><td>...</td><td>0.490951</td><td>0.116987</td><td>0.025143</td></tr><tr><td>VHF</td><td>0.08263</td><td>0.229946</td><td>0.117086</td><td>1</td><td>...</td><td>0.200356</td><td>0.188619</td><td>0.057175</td></tr><tr><td>RVI</td><td>0.641627</td><td>0.194601</td><td>0.28462</td><td>0.264723</td><td>...</td><td>0.729714</td><td>0.181005</td><td>0.051294</td></tr><tr><td>K</td><td>0.641103</td><td>0.262512</td><td>0.480606</td><td>0.211701</td><td>...</td><td>0.72054</td><td>0.241423</td><td>0.033573</td></tr><tr><td>D</td><td>0.589984</td><td>0.364085</td><td>0.301551</td><td>0.23664</td><td>...</td><td>0.741481</td><td>0.27128</td><td>0.040021</td></tr><tr><td>J</td><td>0.589025</td><td>0.090034</td><td>0.615213</td><td>0.142905</td><td>...</td><td>0.565284</td><td>0.16122</td><td>0.019587</td></tr><tr><td>BIAS</td><td>0.75398</td><td>0.215885</td><td>0.774695</td><td>0.21108</td><td>...</td><td>0.812338</td><td>0.201667</td><td>0.03325</td></tr><tr><td>ForceIndex</td><td>0.148226</td><td>0.023868</td><td>0.527503</td><td>0.057149</td><td>...</td><td>0.202753</td><td>0.02134</td><td>0.029512</td></tr><tr><td>VR</td><td>0.388504</td><td>0.215126</td><td>0.30803</td><td>0.302972</td><td>...</td><td>0.514827</td><td>0.219894</td><td>0.018097</td></tr><tr><td>DPO</td><td>0.527409</td><td>0.698932</td><td>0.427081</td><td>0.237592</td><td>...</td><td>0.854124</td><td>0.27802</td><td>0.049276</td></tr><tr><td>NVI</td><td>-0.035288</td><td>0.141327</td><td>0.036469</td><td>0.137088</td><td>...</td><td>0.057865</td><td>0.688242</td><td>0.012894</td></tr><tr><td>PVI</td><td>-0.001064</td><td>-0.000646</td><td>-0.013698</td><td>-0.077327</td><td>...</td><td>-0.001345</td><td>-0.259608</td><td>-0.023317</td></tr><tr><td>ROC</td><td>0.72906</td><td>0.349514</td><td>0.519253</td><td>0.252519</td><td>...</td><td>0.940146</td><td>0.245085</td><td>0.043113</td></tr><tr><td>OBV</td><td>-0.016637</td><td>-0.045237</td><td>-0.040668</td><td>-0.105039</td><td>...</td><td>-0.042494</td><td>-0.233653</td><td>-0.030358</td></tr><tr><td>PSY</td><td>0.468451</td><td>0.343917</td><td>0.379963</td><td>0.250157</td><td>...</td><td>0.669793</td><td>0.309883</td><td>0.046945</td></tr><tr><td>MTM_6</td><td>0.742879</td><td>0.149755</td><td>0.687105</td><td>0.160197</td><td>...</td><td>0.721156</td><td>0.147601</td><td>0.014734</td></tr><tr><td>MTM_12</td><td>0.788774</td><td>0.357106</td><td>0.490951</td><td>0.200356</td><td>...</td><td>1</td><td>0.203693</td><td>0.037635</td></tr><tr><td>CMO</td><td>-0.006458</td><td>0.3441</td><td>0.116987</td><td>0.188619</td><td>...</td><td>0.203693</td><td>1</td><td>0.031895</td></tr><tr><td>ret</td><td>0.01672</td><td>0.041914</td><td>0.025143</td><td>0.057175</td><td>...</td><td>0.037635</td><td>0.031895</td><td>1</td></tr></tbody></table><p>21 rows × 21 columns</p><p><img src='p/corr_3_2.png' alt='' /></p><p></p><h3><a name='header-n1010' class='md-header-anchor '></a>3.3 <strong>6个阿尔法变量</strong>（通过纯数据挖掘得到的阿尔法因子):</h3><p>alpha#6，alpha#12，alpha#23，alpha#28，alpha#54，alpha#101（<em>主要参考了《<strong>WorldQuant Formulaic 101 Alphas</strong>》研究报告中给出的阿尔法因子计算公式，具体见附录</em>）</p><h4><a name='header-n1012' class='md-header-anchor '></a>3.3.1 阿尔法变量描述性统计和箱形图</h4><p>6个阿尔法变量，其中3个变量 alpha12，alpha23，alpha28由于存在异常值，导致箱形图长度较窄。 </p><table><thead><tr><th></th><th>alpha_6</th><th>alpha_12</th><th>alpha_23</th><th>alpha_28</th><th>alpha_54</th><th>alpha_101</th></tr></thead><tbody><tr><td>count</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td><td>2947</td></tr><tr><td>mean</td><td>-0.343985</td><td>-4.692617</td><td>-14.759806</td><td>-0.00005</td><td>-0.533161</td><td>0.068314</td></tr><tr><td>std</td><td>0.385096</td><td>58.739018</td><td>47.081124</td><td>0.000511</td><td>0.312609</td><td>0.581572</td></tr><tr><td>min</td><td>-0.977364</td><td>-378.179</td><td>-479.929</td><td>-0.003782</td><td>-0.993079</td><td>-0.999979</td></tr><tr><td>25%</td><td>-0.650779</td><td>-27.06</td><td>-22.3865</td><td>-0.000269</td><td>-0.826494</td><td>-0.427046</td></tr><tr><td>50%</td><td>-0.399601</td><td>-3.4165</td><td>0</td><td>-0.000038</td><td>-0.573329</td><td>0.090392</td></tr><tr><td>75%</td><td>-0.095957</td><td>15.7185</td><td>0</td><td>0.000158</td><td>-0.241167</td><td>0.592086</td></tr><tr><td>max</td><td>0.92915</td><td>391.866</td><td>302.541</td><td>0.003135</td><td>0</td><td>0.999993</td></tr></tbody></table><p><img src='p/box_3_3.png' alt='' /></p><p></p><h4><a name='header-n1093' class='md-header-anchor '></a>3.3.2 阿尔法变量的条形图和密度曲线</h4><p>如下两图所示，其中3个之前提到的阿尔法变量alpha12，alpha23，alpha28，呈现明显的正态分布，另外三个在区间内则分布比较均匀。
<img src='p/bar_3_3.png' alt='' /></p><p><img src='p/density_3_3.png' alt='' /></p><p></p><h4><a name='header-n1101' class='md-header-anchor '></a>3.3.3 阿尔法变量的相关系数表和热力图</h4><p>6个阿尔法变量与对数收益率的相关系数绝对值有高有低，最高0.07，最低0.007。6个相关系数之间也存在一定的共线性。</p><table><thead><tr><th></th><th>alpha_6</th><th>alpha_12</th><th>alpha_23</th><th>alpha_28</th><th>alpha_54</th><th>alpha_101</th><th>ret</th></tr></thead><tbody><tr><td>alpha_6</td><td>1</td><td>-0.05008</td><td>0.16458</td><td>0.041802</td><td>0.058835</td><td>-0.056188</td><td>-0.027319</td></tr><tr><td>alpha_12</td><td>-0.05008</td><td>1</td><td>0.16686</td><td>0.126117</td><td>0.117021</td><td>-0.19541</td><td>0.002532</td></tr><tr><td>alpha_23</td><td>0.16458</td><td>0.16686</td><td>1</td><td>0.411732</td><td>0.137108</td><td>-0.197584</td><td>-0.037156</td></tr><tr><td>alpha_28</td><td>0.041802</td><td>0.126117</td><td>0.411732</td><td>1</td><td>-0.060792</td><td>0.04374</td><td>0.07416</td></tr><tr><td>alpha_54</td><td>0.058835</td><td>0.117021</td><td>0.137108</td><td>-0.060792</td><td>1</td><td>-0.859041</td><td>-0.007192</td></tr><tr><td>alpha_101</td><td>-0.056188</td><td>-0.19541</td><td>-0.197584</td><td>0.04374</td><td>-0.859041</td><td>1</td><td>0.04816</td></tr><tr><td>ret</td><td>-0.027319</td><td>0.002532</td><td>-0.037156</td><td>0.07416</td><td>-0.007192</td><td>0.04816</td><td>1</td></tr></tbody></table><p><img src='p/corr_3_3.png' alt='' /></p><p></p><h3><a name='header-n1181' class='md-header-anchor '></a>3.4 其他特征变量</h3><p>除前面一共36个特征变量外，在接下来的特征选择中，我们增加其他衍生变量：
1.定义变量<strong>在前d个交易日的变化率</strong>：<img src='p/changed.png' alt='' /></p><p>其中x的参数，我们分别输入之前的10个基本变量，d参数分别输入1，5，10。这样我们分别计算了10个基础变量的前1  个，5个和10个交易日的变化率，共另外得到30个特征变量。</p><p>2.定义一个  <strong>adv20</strong>  变量，即指前20个交易日的平均交易量。</p><p></p><h3><a name='header-n1191' class='md-header-anchor '></a>3.5 数据合并和标准化处理</h3><p>本章最后部分，我们把所有生成的67个特征变量与目标变量<strong>第二天对数收益率</strong>，按时间戳保持一致进行合并。然后对每列数据进行标准化处理，使得最终模型的系数无量纲化，具体公式为：<img src='p/StandardScaler.png' alt='' /> ，其中S为该列数据变量标准差。</p><p></p><h2><a name='header-n1196' class='md-header-anchor '></a>4.特征选择</h2><p><strong>特征选择</strong>本质上是一个变量的<strong>组合优化（combinatorial optimization）</strong>问题。现在我们已经获得了67个特征变量，在建模过程中，每个特征变量有两个可能的状态：&quot;保留&quot;和&quot;被剔除&quot;。</p><p>那么保留下来的特征变量可能的集合个数是<strong>2^67</strong>，如果通过穷举法的方式进行求解，需要耗费大量时间和计算资源，如下图所示：</p><p><img src='p/com_opt.jpg' alt='' /></p><p>所以我们需要较好的特征选择方法，既快速又高效地完成变量的选择，在前面一章我们已经获取所需的全部变量特征并进行了标准化的预处理，用可视化的工具初步分析了各个特征变量的分散性和与目标变量的相关性。</p><p>本章进行特征选择，我们会使用<strong>python</strong>的<strong>scikit-learn模块</strong>提供的部分方法进行特征选择，相关代码也会列出。</p><p></p><h3><a name='header-n1209' class='md-header-anchor '></a>4.1 Filter过滤法（单变量特征筛选）</h3><h4><a name='header-n1210' class='md-header-anchor '></a>4.1.1 Pearson相关系数</h4><p><strong>Pearson 相关系数</strong>是最常用的判断特征和响应变量（response variable）之间的线性关联的标准。在上一章中，我们用计算当前交易日的特征变量与第二天交易日的对数收益率的Pearson相关系数。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">feature_selection</span> <span class="cm-keyword">import</span> <span class="cm-variable">f_regression</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###correlation</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">f</span>, <span class="cm-variable">pval</span> = <span class="cm-variable">f_regression</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">target</span>, <span class="cm-variable">center</span>=<span class="cm-builtin">True</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Corr.'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">f</span>, <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 91px;"></div></div></div></pre><p></p><h4><a name='header-n1216' class='md-header-anchor '></a>4.1.2 距离相关系数（Distance Correlation Coefficient）</h4><p><strong>距离相关系数</strong>是针对 Pearson 相关系数只能表征线性关系的缺点而提出的。其思想是分别构建特征变量和响应变量的欧氏距离矩阵，并由此计算特征变量和响应变量的距离相关系数。详细的定义和计算过程可参考维基百科，由于python中没有提供相关的模块计算距离相关系数，故参考了其他资料，使用了自定义函数。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###calculation the distance correlation</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">dis_corr</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-variable">names</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">dc</span>, <span class="cm-variable">dr</span>, <span class="cm-variable">dvx</span>, <span class="cm-variable">dvy</span> = <span class="cm-variable">dcov_all</span>(<span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>[<span class="cm-variable">i</span>]), <span class="cm-variable">np</span>.<span class="cm-property">array</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">dis_corr</span>.<span class="cm-property">append</span>(<span class="cm-variable">dr</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Dis_Corr'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">dis_corr</span>, <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 136px;"></div></div></div></pre><p></p><h3><a name='header-n1222' class='md-header-anchor '></a>4.2 Wrapper封装法</h3><h4><a name='header-n1223' class='md-header-anchor '></a>4.2.1 基础模型：简单线性回归</h4><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">linear_model</span> <span class="cm-keyword">import</span> <span class="cm-variable">LinearRegression</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###simple linear regression</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lr</span> = <span class="cm-variable">LinearRegression</span>(<span class="cm-variable">normalize</span>=<span class="cm-builtin">True</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lr</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'LR'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">lr</span>.<span class="cm-property">coef_</span>), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p></p><h4><a name='header-n1227' class='md-header-anchor '></a>4.2.2 递归特征消除法（Recursive Feature Elimination, RFE）</h4><p><strong>递归消除特征法</strong>使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。虽然该方法，名称中带有递归，但实质上并没有递归存在，我们使用feature_selection库的RFE类来进行特征选择，具体代码如下：</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">feature_selection</span> <span class="cm-keyword">import</span> <span class="cm-variable">RFE</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#stop the search when 5 features are left(they will get equal scores)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#这里基础模型使用的简单线性回归，目标函数筛选到5个变量为止</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###calculate the Recursive Feature Elimination</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rfe</span> = <span class="cm-variable">RFE</span>(<span class="cm-variable">lr</span>, <span class="cm-variable">n_features_to_select</span>=<span class="cm-number">5</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rfe</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'RFE'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">rfe</span>.<span class="cm-property">ranking_</span>.<span class="cm-property">astype</span>(<span class="cm-builtin">float</span>), <span class="cm-variable">names</span>, <span class="cm-variable">order</span>=<span class="cm-operator">-</span><span class="cm-number">1</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 159px;"></div></div></div></pre><p></p><h3><a name='header-n1233' class='md-header-anchor '></a>4.3 Embedded 嵌入法</h3><h4><a name='header-n1234' class='md-header-anchor '></a>4.3.1 随机森林（Random Forest）</h4><p>随机森林算法是把决策树（decision tree）和自助重抽样法（bootstrapping resampling）结合起来的分类或者回归算法。其思想是通过对训练集进行重抽样的方法生成大量的决策树，再把决策树组合起来，从而减少噪音的干扰和过拟合的可能。在 scikit-learn 模块的 ensemble 类中，用随机森林算法进行回归的目标函数是均方差误差函数（Mean Square Error）。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">ensemble</span> <span class="cm-keyword">import</span> <span class="cm-variable">RandomForestRegressor</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###Random Forest</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rf</span> = <span class="cm-variable">RandomForestRegressor</span>(<span class="cm-variable">random_state</span>=<span class="cm-number">101</span>) <span class="cm-comment">#加入随机种子数，确保每次输出结果相同</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rf</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'RF'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">rf</span>.<span class="cm-property">feature_importances_</span>, <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p></p><h4><a name='header-n1240' class='md-header-anchor '></a>4.3.2 基于正则化的线性回归（Regularization-Based Linear Regression）</h4><p>首先介绍两个模型结果的评判标准：</p><p><strong>赤池信息准则（Akaike information criterion, AIC）</strong> 和 <strong>贝叶斯信息准则（Bayesian Information Criterions, BIC）</strong></p><p>AIC和BIC有相近的数学表达式：</p><p><strong>AIC = 2k - 2ln(L)</strong>      <strong>BIC = ln(n)*k - 2ln(L)</strong></p><p>其中k为参数数目，L是似然函数（likelihood function）, n是数据中观测值的数量。</p><p>AIC 和 BIC 的表达式中均包含了模型复杂度惩罚项（2k和ln(n)* k）和 最大似然函数项（ln(L)）。不同的地方在于，在 BIC 的表达式中，惩罚项的权重随观测值的增加而增加。因此当观测值数量较大时，只有显著关联的特征变量才会被保留，从而降低模型的复杂性。<strong>在 AIC 的维基百科词条中，提到了 AIC 在实践中的效果一般优于 BIC</strong>。</p><p>在建模时，我们可以通过最小化 AIC 或 BIC 来选择模型的最优参数。由表达式可以看出，AIC 和 BIC 倾向于复杂度低（k越小越好）和符合先验假设（L越大越好）的模型。在简单线性回归中，似然函数L是依据残差服从正态分布的先验假设构建的，即如果特征变量的加入能够使残差更接近正态分布，则认为这个特征能够显著改善线性回归模型。</p><p></p><p>回归模型介绍：</p><p><strong>Lasso回归（Least absolute shrinkage and selection operator）</strong>和 <strong>岭回归（Ridge）</strong></p><p>在优化理论（optimization theory）中，<strong>正则化（regularization）</strong>是一类通过对解施加先验约束把不适定问题（ill-posed problem）转化为适定问题的常用技巧。例如，在线性回归模型中，当用最小二乘法估计线性回归的系数β时，如果自变量存在共线性，系数的估计值将具有较大的方差，因而会影响后续参数的统计检验。如果在最小二乘法的参数估计表达式中添加L1正则项 <strong>λ|β|</strong>，则称为Lasso线性回归模型：</p><p><img src='p/lasso.png' alt='' /></p><p>如果添加L2正则项<strong>λβ^Tβ</strong> ，则称为岭回归模型（Ridge Regression）：</p><p><img src='p/ridge.png' alt='' /></p><p>在线性回归的系数估计中，正则化处理在改善问题的适定性的同时，也会使得系数的估计有偏（biased estimation），因此在选择正则化项的权重λ时，一般的原则是在问题足够适定的前提下，λ应该尽可能小。在接下来的实现中，我们使用上面提到的AIC和BIC来确定正则化项的权重。另外，L2正则化和L1正则化对解施加的是不同的先验约束：L2正则化会令解出现集中分布的特性，而L1正则化则会令解出现稀疏的特性。在Lasso回归中，因为L1正则化会令部分的系数趋近于0，因此也是一种常用的特征选择方法。</p><p><strong>随机Lasso回归（RandomizedLasso）</strong></p><p>在统计学中，我们通常把这类和自变量和响应变量均存在显著相关性的变量称为<strong>混淆变量（confounding variable）</strong>。在Lasso回归中，如果存在自变量共线性的问题，则哪一个特征维度被剔除将取决于特征选择子集构建的顺序，从而造成特征选择结果的不确定性。</p><p>为了减少 Lasso 回归中特征选择顺序的影响，Python的 scikit-learn 模块 linear_model类 中提供了一个 RandomizedLasso 类。其思路是对训练集的数据进行多次重抽样，从而得到一系列特征选择的子集，再对子集中各个特征变量出现的频率进行统计，剔除掉出现频率低的特征变量。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span>​</span>x</span></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">linear_model</span> <span class="cm-keyword">import</span> <span class="cm-variable">LassoLarsIC</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###lasso regression based on AIC</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lasso_aic</span> = <span class="cm-variable">LassoLarsIC</span>(<span class="cm-variable">criterion</span>=<span class="cm-string">'aic'</span>, <span class="cm-variable">max_iter</span>=<span class="cm-number">50000</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lasso_aic</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Lasso_AIC'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">lasso_aic</span>.<span class="cm-property">coef_</span>), <span class="cm-variable">names</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###lasso regression based on BIC</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lasso_bic</span> = <span class="cm-variable">LassoLarsIC</span>(<span class="cm-variable">criterion</span>=<span class="cm-string">'bic'</span>, <span class="cm-variable">max_iter</span>=<span class="cm-number">50000</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lasso_bic</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Lasso_BIC'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">lasso_bic</span>.<span class="cm-property">coef_</span>), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 227px;"></div></div></div></pre><p>-</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">linear_model</span> <span class="cm-keyword">import</span> <span class="cm-variable">RandomizedLasso</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###randomized lasso regression</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rlasso</span> = <span class="cm-variable">RandomizedLasso</span>(<span class="cm-variable">alpha</span>=<span class="cm-number">0.07</span>,  <span class="cm-variable">random_state</span>=<span class="cm-number">22</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rlasso</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Stability'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">rlasso</span>.<span class="cm-property">scores_</span>), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p>-</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">linear_model</span> <span class="cm-keyword">import</span> <span class="cm-variable">Ridge</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">###ridge regression</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ridge</span> = <span class="cm-variable">Ridge</span>(<span class="cm-variable">alpha</span>=<span class="cm-number">7</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ridge</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'Ridge'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">ridge</span>.<span class="cm-property">coef_</span>), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p><em>由于未知原因，<strong>Lasso_BIC</strong> 方法中的所有特征变量前的系数为 0，故删去。</em></p><p></p><h3><a name='header-n1288' class='md-header-anchor '></a>4.4 集成特征打分器（Ensemble Feature Grader, 以下简称EFG）</h3><p>特征选择的本质上是求解一个计算量随特征变量个数呈指数增长的组合优化问题。基于不同的子集搜索和评价标准，不同的方法给出的都只是一个近似最优解，而解的合理性也将受方法本身的局限性所影响。在真实的数据分析中，如果我们通过特征工程产生大量的特征变量，数据集中必然包含噪音，共线性，非线性相关等问题。</p><p>因此，为了系统化地进行特征选择，获得更为合理的相关特征变量子集，在这里我们借鉴机器学习里面的<strong>集成学习（ensemble learning）</strong>的思想，提出一个集成特征打分器（以下称EFG）。其主要思路是，根据以上特征选择的方法对特征进行打分（分数的取值范围为0到1），观察特征变量在不同方法下的得分，进而计算其总得分，以尽量减少数据和单一特征选择方法引起的问题，并改善特征选择的效果。</p><p>最终得到的结果如下表所示，各特征变量按Mean这一列从大到小排列。</p><table><thead><tr><th></th><th>Corr.</th><th>Dis_Corr</th><th>LR</th><th>Lasso_AIC</th><th>RF</th><th>RFE</th><th>Ridge</th><th>Mean</th></tr></thead><tbody><tr><td>alpha_28</td><td>1</td><td>0.32</td><td>0.02</td><td>1</td><td>0.62</td><td>0.94</td><td>1</td><td>0.7</td></tr><tr><td>daily_gain_1</td><td>0.22</td><td>0.18</td><td>0.03</td><td>0.66</td><td>0.52</td><td>0.92</td><td>0.6</td><td>0.45</td></tr><tr><td>AMA</td><td>0.32</td><td>0.57</td><td>0.02</td><td>0.02</td><td>0.95</td><td>0.74</td><td>0.45</td><td>0.44</td></tr><tr><td>DPO</td><td>0.44</td><td>0.57</td><td>0.01</td><td>0.18</td><td>0.76</td><td>0.63</td><td>0.19</td><td>0.4</td></tr><tr><td>close</td><td>0.42</td><td>0.18</td><td>1</td><td>0</td><td>0.16</td><td>1</td><td>0.07</td><td>0.4</td></tr><tr><td>close_5</td><td>0.36</td><td>0.36</td><td>0.03</td><td>0.19</td><td>0.29</td><td>1</td><td>0.51</td><td>0.39</td></tr><tr><td>alpha_101</td><td>0.42</td><td>0.05</td><td>0.01</td><td>0.59</td><td>0.43</td><td>0.79</td><td>0.43</td><td>0.39</td></tr><tr><td>daily_region_1</td><td>0.76</td><td>0.19</td><td>0.01</td><td>0.13</td><td>0.85</td><td>0.53</td><td>0.2</td><td>0.38</td></tr><tr><td>CMO</td><td>0.18</td><td>0.55</td><td>0.01</td><td>0.3</td><td>0.63</td><td>0.68</td><td>0.22</td><td>0.37</td></tr><tr><td>volume_1</td><td>0.01</td><td>0.05</td><td>0.03</td><td>0.59</td><td>0.35</td><td>0.82</td><td>0.76</td><td>0.37</td></tr><tr><td>price</td><td>0.64</td><td>0.3</td><td>0.01</td><td>0.38</td><td>0.4</td><td>0.66</td><td>0.2</td><td>0.37</td></tr><tr><td>daily_opengain_5</td><td>0.15</td><td>0.2</td><td>0.01</td><td>0.28</td><td>0.84</td><td>0.84</td><td>0.23</td><td>0.36</td></tr><tr><td>BIAS</td><td>0.2</td><td>0.34</td><td>0.01</td><td>0.2</td><td>0.72</td><td>0.71</td><td>0.21</td><td>0.34</td></tr><tr><td>daily_region</td><td>0.5</td><td>1</td><td>0</td><td>0.07</td><td>0.65</td><td>0.15</td><td>0.03</td><td>0.34</td></tr><tr><td>daily_gain_5</td><td>0.61</td><td>0.17</td><td>0</td><td>0.32</td><td>0.72</td><td>0.31</td><td>0.16</td><td>0.33</td></tr><tr><td>high_5</td><td>0.23</td><td>0.42</td><td>0.02</td><td>0</td><td>0.58</td><td>0.76</td><td>0.28</td><td>0.33</td></tr><tr><td>MACD</td><td>0.05</td><td>0.33</td><td>0.03</td><td>0</td><td>0.71</td><td>0.69</td><td>0.53</td><td>0.33</td></tr><tr><td>daily_opengain</td><td>0</td><td>0.22</td><td>0.01</td><td>0.39</td><td>0.57</td><td>0.85</td><td>0.23</td><td>0.32</td></tr><tr><td>VHF</td><td>0.59</td><td>0.18</td><td>0</td><td>0.1</td><td>0.97</td><td>0.26</td><td>0.06</td><td>0.31</td></tr><tr><td>ROC</td><td>0.34</td><td>0.39</td><td>0.01</td><td>0.05</td><td>0.74</td><td>0.44</td><td>0.22</td><td>0.31</td></tr><tr><td>volume</td><td>0.03</td><td>0.14</td><td>0.02</td><td>0.06</td><td>0.47</td><td>0.9</td><td>0.52</td><td>0.31</td></tr><tr><td>high</td><td>0.41</td><td>0.2</td><td>0.5</td><td>0</td><td>0.06</td><td>1</td><td>0.02</td><td>0.31</td></tr><tr><td>amount_1</td><td>0.02</td><td>0.06</td><td>0.03</td><td>0.44</td><td>0.2</td><td>0.81</td><td>0.64</td><td>0.31</td></tr><tr><td>alpha_54</td><td>0.01</td><td>0</td><td>0.01</td><td>0.45</td><td>0.46</td><td>0.77</td><td>0.3</td><td>0.29</td></tr><tr><td>low</td><td>0.45</td><td>0.17</td><td>0.37</td><td>0</td><td>0</td><td>1</td><td>0.01</td><td>0.29</td></tr><tr><td>price_10</td><td>0.2</td><td>0.15</td><td>0.01</td><td>0.27</td><td>0.46</td><td>0.58</td><td>0.28</td><td>0.28</td></tr><tr><td>close_1</td><td>0.22</td><td>0.21</td><td>0.03</td><td>0</td><td>0.26</td><td>0.87</td><td>0.37</td><td>0.28</td></tr><tr><td>daily_gain</td><td>0.22</td><td>0.18</td><td>0.02</td><td>0</td><td>0.47</td><td>0.73</td><td>0.3</td><td>0.27</td></tr><tr><td>price_1</td><td>0.15</td><td>0</td><td>0.01</td><td>0.18</td><td>0.72</td><td>0.56</td><td>0.19</td><td>0.26</td></tr><tr><td>low_5</td><td>0.07</td><td>0.37</td><td>0.01</td><td>0</td><td>0.21</td><td>0.98</td><td>0.21</td><td>0.26</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>volume_10</td><td>0.09</td><td>0.05</td><td>0.02</td><td>0.08</td><td>0.37</td><td>0.6</td><td>0.37</td><td>0.23</td></tr><tr><td>close_10</td><td>0.12</td><td>0.45</td><td>0.02</td><td>0</td><td>0.32</td><td>0.47</td><td>0.2</td><td>0.23</td></tr><tr><td>daily_gain_10</td><td>0.01</td><td>0.12</td><td>0.01</td><td>0.03</td><td>0.89</td><td>0.45</td><td>0.09</td><td>0.23</td></tr><tr><td>RVI</td><td>0.48</td><td>0.15</td><td>0</td><td>0.11</td><td>0.48</td><td>0.32</td><td>0.08</td><td>0.23</td></tr><tr><td>low_10</td><td>0.06</td><td>0.43</td><td>0.02</td><td>0</td><td>0.28</td><td>0.48</td><td>0.3</td><td>0.22</td></tr><tr><td>high_1</td><td>0.03</td><td>0.2</td><td>0.01</td><td>0.2</td><td>0.3</td><td>0.52</td><td>0.22</td><td>0.21</td></tr><tr><td>low_1</td><td>0.21</td><td>0.19</td><td>0</td><td>0</td><td>0.53</td><td>0.19</td><td>0.37</td><td>0.21</td></tr><tr><td>daily_region_10</td><td>0.35</td><td>0.21</td><td>0</td><td>0</td><td>0.54</td><td>0.27</td><td>0.04</td><td>0.2</td></tr><tr><td>daily_region_5</td><td>0.32</td><td>0.28</td><td>0</td><td>0</td><td>0.65</td><td>0.16</td><td>0.01</td><td>0.2</td></tr><tr><td>adv_20</td><td>0</td><td>0.15</td><td>0.01</td><td>0</td><td>0.56</td><td>0.55</td><td>0.12</td><td>0.2</td></tr><tr><td>NVI</td><td>0.03</td><td>0.47</td><td>0</td><td>0</td><td>0.45</td><td>0.35</td><td>0.08</td><td>0.2</td></tr><tr><td>OBV</td><td>0.17</td><td>0.26</td><td>0.01</td><td>0.01</td><td>0.3</td><td>0.4</td><td>0.21</td><td>0.19</td></tr><tr><td>ForceIndex</td><td>0.16</td><td>0.24</td><td>0</td><td>0.07</td><td>0.61</td><td>0.18</td><td>0.05</td><td>0.19</td></tr><tr><td>daily_opengain_1</td><td>0.05</td><td>0.22</td><td>0</td><td>0.09</td><td>0.84</td><td>0.13</td><td>0</td><td>0.19</td></tr><tr><td>daily_opengain_10</td><td>0.01</td><td>0.24</td><td>0</td><td>0</td><td>0.94</td><td>0.06</td><td>0.01</td><td>0.18</td></tr><tr><td>alpha_23</td><td>0.25</td><td>0.18</td><td>0</td><td>0.15</td><td>0.26</td><td>0.34</td><td>0.1</td><td>0.18</td></tr><tr><td>VR</td><td>0.06</td><td>0.09</td><td>0.01</td><td>0.16</td><td>0.41</td><td>0.37</td><td>0.14</td><td>0.18</td></tr><tr><td>PVI</td><td>0.1</td><td>0.31</td><td>0.01</td><td>0</td><td>0.23</td><td>0.42</td><td>0.16</td><td>0.18</td></tr><tr><td>alpha_6</td><td>0.14</td><td>0.05</td><td>0</td><td>0.01</td><td>1</td><td>0</td><td>0</td><td>0.17</td></tr><tr><td>MTM_12</td><td>0.26</td><td>0.47</td><td>0</td><td>0</td><td>0.22</td><td>0.1</td><td>0.04</td><td>0.16</td></tr><tr><td>PSY</td><td>0.4</td><td>0.11</td><td>0</td><td>0.12</td><td>0</td><td>0.39</td><td>0.11</td><td>0.16</td></tr><tr><td>volume_5</td><td>0.27</td><td>0.11</td><td>0</td><td>0.08</td><td>0.31</td><td>0.23</td><td>0.03</td><td>0.15</td></tr><tr><td>opn_10</td><td>0.07</td><td>0.48</td><td>0</td><td>0.14</td><td>0.22</td><td>0.02</td><td>0.08</td><td>0.14</td></tr><tr><td>TRIX</td><td>0.11</td><td>0.22</td><td>0.01</td><td>0</td><td>0.2</td><td>0.29</td><td>0.12</td><td>0.14</td></tr><tr><td>amount_5</td><td>0.27</td><td>0.14</td><td>0</td><td>0</td><td>0.27</td><td>0.24</td><td>0.07</td><td>0.14</td></tr><tr><td>D</td><td>0.29</td><td>0.12</td><td>0</td><td>0</td><td>0.26</td><td>0.11</td><td>0.04</td><td>0.12</td></tr><tr><td>price_5</td><td>0</td><td>0.02</td><td>0</td><td>0.04</td><td>0.47</td><td>0.21</td><td>0.05</td><td>0.11</td></tr><tr><td>alpha_12</td><td>0</td><td>0.23</td><td>0</td><td>0</td><td>0.45</td><td>0.05</td><td>0.01</td><td>0.11</td></tr><tr><td>K</td><td>0.2</td><td>0.11</td><td>0</td><td>0</td><td>0.33</td><td>0.03</td><td>0</td><td>0.1</td></tr><tr><td>J</td><td>0.07</td><td>0.09</td><td>0</td><td>0.03</td><td>0.41</td><td>0.08</td><td>0.04</td><td>0.1</td></tr></tbody></table><p>67 rows × 8 columns</p><p></p><h2><a name='header-n1920' class='md-header-anchor '></a>5.模型和策略</h2><h3><a name='header-n1921' class='md-header-anchor '></a>5.1 K-means 聚类分析和样本内检验</h3><p>我们使用最经典的<strong>非监督学习方式——K-means聚类分析</strong>，来进行对目标变量的预测判断（简单来说只要知道涨跌情况这一个二元分类变量），所以K-means 需要输出的聚类个数为2个。至于输入的变量，我们依据之前的EFG情况，从大到小分别选取1个到67个特征变量，并进行了在样本内的检验。最后聚类内较高收益率按特征数量分布的情况，如下图所示：</p><p>最高值出现在图中最前面,在选3个特征变量（<em>alpha_28</em>、<em>AMA</em>、<em>daily_gain_1</em>）时，对数收益率到达最高的<strong>2.048</strong>, 说明了EFG的有效性，提供了较好的特征变量。总体来看收益率随特征变量的个数变化呈V字型，前期到达最高值后下降到谷底后又迅速上升。<strong>个别数值出现异常偏离，可能是特征变量之间存在严重的共线性，至于后面的随着特征个数增加收益率逐渐上升无法做出合理解释</strong>。</p><p><img src='p/number_features.png' alt='' /></p><p></p><h3><a name='header-n1930' class='md-header-anchor '></a>5.2 策略</h3><p>基于之前分析结果，选择前3个特征变量<em>alpha_28</em>、<em>AMA</em>、<em>daily_gain_1</em>作为K-means聚类分析的输入值，把目标变量分为两类，并对聚类的结果进行收益率和波动率的统计，证明得到的聚类存在两个明显不同的收益率分布，如下表所示：</p><p>可以发现两个聚类平均收益率存在明显差距，而平均的标准差差别较小。</p><table><thead><tr><th></th><th>trade_days</th><th>Rc.mean</th><th>Rc.std</th></tr></thead><tbody><tr><td>all</td><td>2946</td><td>0.00043</td><td>0.01828</td></tr><tr><td>cluster1</td><td>1279</td><td>0.00163</td><td>0.01859</td></tr><tr><td>cluster2</td><td>1667</td><td>-0.00049</td><td>0.01798</td></tr></tbody></table><p>我们选取cluster1聚类中的目标变量作为买入指标，即输入当天交易日的三个特征<em>alpha_28</em>、<em>AMA</em>、<em>daily_gain_1</em>，如果被聚类输出为cluster1，则选择买入或继续全仓持有，否则被归类到cluster2，选择卖出。具体的收益率曲线图如下所示：</p><p>可以从图中看出，该策略有着10年以上持续稳定的收益并且经历了牛市和熊市的多重洗礼，平均年化收益率接近17%，该策略发生的最大回撤是在<strong>2008-05-28至2008-11-24</strong> 对数收益率下降了0.2713，转换为普通收益率就是收益<strong>下降了31.17%</strong>，这个回撤稍微有点大。 最终策略的总收益率是<strong>2.08（对数收益率）</strong>，<strong>简单来说相当于你2005年4月6日持有指数1000点，到了2017年5月18日持有指数已经变为8056点</strong>。</p><p><img src='p/yield.png' alt='' /></p><p>同期基于cluster2中的目标变量的策略收益率如下：</p><p><img src='p/yield2.png' alt='' /></p><p></p><h2><a name='header-n1968' class='md-header-anchor '></a>6.模型稳健性检验</h2><h3><a name='header-n1969' class='md-header-anchor '></a>6.1 交叉验证与样本外检验</h3><h4><a name='header-n1970' class='md-header-anchor '></a>6.1.1 交叉验证（Cross Validation）</h4><p><strong>交叉验证</strong>亦称为循环估计， 是用来验证分类器/回归/聚类算法的性能的一种统计分析方法。它用于分析机器学习算法的泛化能力(generalization)。其基本思想是将原始数据(data set)进行分组，一部分作为训练集（training set)，一部分作为测试集 (testing set)。首先利用训练集对算法进行训练，再利用测试集来检验得到的模型(model)，以此为指标来评价算法的性能。</p><p></p><p><strong>K折交叉验证（K-folder cross-validation）</strong>
将原始数据分成K个子集（一般是均分），将每个子集数据分别做一次测试集 （testing test)，其余的K-1组子集数据作为训练集（training test)，这样会得到K个模型，用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标。交叉验证重复k次，每次选择一个子集作为测试集，并将k次的平均交叉验证识别正确率作为结果。</p><p>优点：所有的样本都被作为了训练集和测试集，每个样本都被验证一次。通常使用ten-folder。</p><p></p><p><strong>实际操作——十折交叉验证</strong>
由于聚类是把数据集分成两类，我们将目标变量对数收益率这一连续变量转换为简单的二元分类变量（binary variable）。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#把收益率这一连续变量转换为分类变量</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">is_up</span>(<span class="cm-variable">n</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">if</span> <span class="cm-variable">n</span> <span class="cm-operator">&gt;</span> <span class="cm-number">0</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">return</span> <span class="cm-number">1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">else</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">return</span> <span class="cm-number">0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span> = <span class="cm-variable">hs300</span>.<span class="cm-property">target</span>.<span class="cm-property">map</span>(<span class="cm-variable">is_up</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 181px;"></div></div></div></pre><p></p><p><strong>全部特征变量加入的十折交叉验证</strong></p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">cross_validation</span> <span class="cm-keyword">import</span> <span class="cm-variable">cross_val_score</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span> <span class="cm-keyword">import</span> <span class="cm-variable">cluster</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">scores1</span> = <span class="cm-variable">pd</span>.<span class="cm-property">Series</span>(<span class="cm-variable">cross_val_score</span>(<span class="cm-variable">k_means</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">data</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span>, <span class="cm-variable">cv</span>=<span class="cm-number">10</span>, <span class="cm-variable">scoring</span>=<span class="cm-string">'accuracy'</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">scores1</span>.<span class="cm-property">plot</span>(<span class="cm-variable">kind</span>=<span class="cm-string">'line'</span>, <span class="cm-variable">style</span>=<span class="cm-string">'r-'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">title</span>(<span class="cm-string">'accuracy changed by different subsets'</span>,<span class="cm-variable">fontsize</span>=<span class="cm-number">20</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 159px;"></div></div></div></pre><p><img src='p/cv_1.png' alt='' /></p><p></p><p><strong>Top3特征变量加入的十折交叉验证</strong></p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">hs300</span>.<span class="cm-property">data3</span> = <span class="cm-variable">pd</span>.<span class="cm-property">concat</span>([<span class="cm-variable">hs300</span>[<span class="cm-string">'AMA'</span>],<span class="cm-variable">hs300</span>[<span class="cm-string">'alpha_28'</span>],<span class="cm-variable">hs300</span>[<span class="cm-string">'daily_gain_1'</span>]], <span class="cm-variable">axis</span>=<span class="cm-number">1</span>)</span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">scores2</span> = <span class="cm-variable">pd</span>.<span class="cm-property">Series</span>(<span class="cm-variable">cross_val_score</span>(<span class="cm-variable">k_means</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">data3</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span>, <span class="cm-variable">cv</span>=<span class="cm-number">10</span>, <span class="cm-variable">scoring</span>=<span class="cm-string">'accuracy'</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">scores2</span>.<span class="cm-property">plot</span>(<span class="cm-variable">kind</span>=<span class="cm-string">'line'</span>, <span class="cm-variable">style</span>=<span class="cm-string">'r-'</span>,<span class="cm-variable">ylim</span>=[<span class="cm-number">0.40</span>,<span class="cm-number">0.65</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">title</span>(<span class="cm-string">'accuracy changed by different subsets'</span>,<span class="cm-variable">fontsize</span>=<span class="cm-number">20</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 136px;"></div></div></div></pre><p><img src='p/cv_2.png' alt='' /></p><p>通过上述两张图对比可以明显看出，加入top3特征变量的十折交叉验证准确度的标准差（<strong>0.02578</strong>）明显小于加入全部特征变量的标准差（<strong>0.05666</strong>），说明<strong>通过特征选择EFG最后筛选出来的特征变量，能有效提升模型的预测准确率的稳定性</strong>。</p><p></p><h4><a name='header-n2004' class='md-header-anchor '></a>6.1.2 样本外检验（Out of Sample Test）</h4><p><strong>样本外检验</strong>是防止曲线拟合的一种实际检验方法，因为我们不知道市场将来走向会如何。我们最终交易的策略依靠的是时刻变化的动态数据，而不是拿历史数据来回测。</p><p><strong>样本外检验的作用</strong>：首先回测是在给定的测试区间内。然后同样的测试运行在一个新的测试周期并使用不同的样本数据，因此得名样本外检验。如果参数或设置在第一个区间内过度优化了，那么在新的区间性能表现不会很优异。</p><p></p><p><strong>实际操作——样本外检验</strong></p><p><strong>加入所有特征变量的样本外检验</strong></p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span> <span class="cm-keyword">import</span> <span class="cm-variable">cluster</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">y_pred1</span> = <span class="cm-variable">k_means</span>.<span class="cm-property">predict</span>(<span class="cm-variable">out_hs300</span>.<span class="cm-property">data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">metrics</span> <span class="cm-keyword">import</span> <span class="cm-variable">accuracy_score</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">accuracy_score</span>(<span class="cm-variable">out_hs300</span>.<span class="cm-property">target_c</span>, <span class="cm-variable">y_pred1</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 136px;"></div></div></div></pre><p></p><p><strong>加入Top3特征变量的样本外检验</strong></p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">out_hs300</span>.<span class="cm-property">data3</span> = <span class="cm-variable">pd</span>.<span class="cm-property">concat</span>([<span class="cm-variable">out_hs300</span>[<span class="cm-string">'AMA'</span>], <span class="cm-variable">out_hs300</span>[<span class="cm-string">'alpha_28'</span>], <span class="cm-variable">out_hs300</span>[<span class="cm-string">'daily_gain_1'</span>]], <span class="cm-variable">axis</span>=<span class="cm-number">1</span>)</span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">k_means</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data3</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">y_pred2</span> = <span class="cm-variable">k_means</span>.<span class="cm-property">predict</span>(<span class="cm-variable">out_hs300</span>.<span class="cm-property">data3</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">accuracy_score</span>(<span class="cm-variable">out_hs300</span>.<span class="cm-property">target_c</span>, <span class="cm-variable">y_pred2</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p>后者经过集成学习筛选的变量的聚类分析预测准确度（<strong>0.6522</strong>）明显高于前者（<strong>0.4348</strong>），说明<strong>特征选择EFG最后筛选出来的特征变量，能有效提升模型的预测准确率</strong>。</p><p></p><h3><a name='header-n2025' class='md-header-anchor '></a>6.2 集成学习中各子模型的预测效果，与集成学习的区别</h3><p>在这一节中，我们来比较之前集成学习中各个子模型的预测效果。主要思路是取各模型下的前三个变量作为聚类分析的输入值，分别比较各模型的累积收益率和十折交叉验证的结果。</p><p></p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span> <span class="cm-keyword">import</span> <span class="cm-variable">cluster</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">yield_cluster</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-builtin">len</span>(<span class="cm-variable">col_names</span>)):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">temp</span> = <span class="cm-variable">EFG</span>[<span class="cm-variable">col_names</span>[<span class="cm-variable">i</span>]].<span class="cm-property">sort_values</span>(<span class="cm-variable">ascending</span>=<span class="cm-builtin">False</span>).<span class="cm-property">index</span>[:<span class="cm-number">3</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">input_data</span> = <span class="cm-variable">hs300</span>[<span class="cm-variable">temp</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>) &nbsp; </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span>.<span class="cm-property">fit</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">test_labels</span> = <span class="cm-variable">k_means</span>.<span class="cm-property">predict</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-builtin">long</span>, <span class="cm-variable">short</span> = ( <span class="cm-variable">test_labels</span> == <span class="cm-number">1</span>), ( <span class="cm-variable">test_labels</span> == <span class="cm-number">0</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">original_data</span> = <span class="cm-variable">pd</span>.<span class="cm-property">read_excel</span>(<span class="cm-string">'沪深300.xlsx'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">date</span> = <span class="cm-variable">pd</span>.<span class="cm-property">to_datetime</span>(<span class="cm-variable">pd</span>.<span class="cm-property">Series</span>(<span class="cm-variable">original_data</span>[<span class="cm-string">'日期'</span>][<span class="cm-number">60</span>:<span class="cm-number">3006</span>].<span class="cm-property">values</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">res</span> = <span class="cm-variable">pd</span>.<span class="cm-property">DataFrame</span>({<span class="cm-string">'date'</span>:<span class="cm-variable">date</span>,<span class="cm-string">'return'</span>:<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>}).<span class="cm-property">set_index</span>(<span class="cm-string">'date'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">predicted_return1</span> = <span class="cm-variable">res</span>[<span class="cm-string">'return'</span>].<span class="cm-property">multiply</span>(<span class="cm-builtin">long</span>) </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">predicted_return2</span> = <span class="cm-variable">res</span>[<span class="cm-string">'return'</span>].<span class="cm-property">multiply</span>(<span class="cm-variable">short</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">yield_cluster</span>.<span class="cm-property">append</span>([<span class="cm-variable">predicted_return1</span>.<span class="cm-property">cumsum</span>()[<span class="cm-builtin">len</span>(<span class="cm-variable">date</span>)<span class="cm-operator">-</span><span class="cm-number">1</span>], <span class="cm-variable">predicted_return2</span>.<span class="cm-property">cumsum</span>()[<span class="cm-builtin">len</span>(<span class="cm-variable">date</span>)<span class="cm-operator">-</span><span class="cm-number">1</span>]])</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 340px;"></div></div></div></pre><table><thead><tr><th style='text-align:left;' ></th><th>cluster1</th><th>cluster2</th></tr></thead><tbody><tr><td style='text-align:left;' >Corr.</td><td>-1.54184</td><td>2.810479</td></tr><tr><td style='text-align:left;' >Dis_Corr</td><td>1.685098</td><td>-0.41646</td></tr><tr><td style='text-align:left;' >LR</td><td>-0.129471</td><td>1.398109</td></tr><tr><td style='text-align:left;' >Lasso_AIC</td><td>-0.842357</td><td>2.110995</td></tr><tr><td style='text-align:left;' >RF</td><td>1.138299</td><td>0.130339</td></tr><tr><td style='text-align:left;' >RFE</td><td>-0.206897</td><td>1.475535</td></tr><tr><td style='text-align:left;' >Ridge</td><td>0.517117</td><td>0.751521</td></tr><tr><td style='text-align:left;' >Stability</td><td>-0.304127</td><td>1.572765</td></tr><tr><td style='text-align:left;' ><strong>Mean</strong></td><td>-0.89173</td><td><strong>2.160368</strong></td></tr></tbody></table><p><img src='p/son_models1.png' alt='' /></p><p>上表和上图表示的是各个子模型聚类分析后的两个聚类下的累积收益率，可以明显看到最后一行<strong>Mean</strong>（集成学习）<strong>2.16</strong>的对数收益率处于所有模型中的第二，说明<strong>集成学习后的模型收益率较高</strong>。</p><p></p><table><thead><tr><th></th><th>accuracy</th><th>std</th></tr></thead><tbody><tr><td>Corr.</td><td>0.523046</td><td>0.040418</td></tr><tr><td>Dis_Corr</td><td>0.474897</td><td>0.0687</td></tr><tr><td>LR</td><td>0.500656</td><td>0.032538</td></tr><tr><td>Lasso_AIC</td><td>0.499633</td><td>0.025259</td></tr><tr><td>RF</td><td>0.464048</td><td>0.043179</td></tr><tr><td>RFE</td><td>0.489453</td><td>0.031453</td></tr><tr><td>Ridge</td><td>0.514911</td><td>0.050615</td></tr><tr><td>Stability</td><td>0.50951</td><td>0.055883</td></tr><tr><td><strong>Mean</strong></td><td><strong>0.504064</strong></td><td><strong>0.025649</strong></td></tr></tbody></table><p><img src='p/son_models2.png' alt='' /></p><p>上表和上图表示的是各个模型十折交叉验证下准确率的平均值和标准差，可以明显看到最后一行<strong>Mean</strong>的平均准确率（蓝色条形图）<strong>稍大于0.5</strong> 排名各模型第四，且它的准确率标准差（红线）<strong>0.0256</strong> 排名第二，从十折交叉验证结果来看，<strong>集成学习后的模型准确率和稳定性都较高</strong>。</p><p></p><h3><a name='header-n2125' class='md-header-anchor '></a>6.3 目标变量转换为分类变量</h3><p>在这一节中，我们把原先的预测变量即第二天的收益率（<strong>数值型</strong>）转换为<strong>二元分类变量（上涨为1，下跌为0）</strong>，然后进行之前类似的集成学习训练。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#logstic回归</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">linear_model</span> <span class="cm-keyword">import</span> <span class="cm-variable">LogisticRegression</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lr</span> = <span class="cm-variable">LogisticRegression</span>(<span class="cm-variable">random_state</span>=<span class="cm-number">101</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">lr</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>,<span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'LR'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">lr</span>.<span class="cm-property">coef_</span>[<span class="cm-number">0</span>]), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">#SVM向量支持机</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">svm</span> <span class="cm-keyword">import</span> <span class="cm-variable">SVC</span>  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">svm</span> = <span class="cm-variable">SVC</span>(<span class="cm-variable">kernel</span>=<span class="cm-string">'linear'</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">svm</span>.<span class="cm-property">fit</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span>)  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">ranks</span>[<span class="cm-string">'SVM'</span>] = <span class="cm-variable">rank_to_dict</span>(<span class="cm-variable">np</span>.<span class="cm-property">abs</span>(<span class="cm-variable">svm</span>.<span class="cm-property">coef_</span>[<span class="cm-number">0</span>]), <span class="cm-variable">names</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></pre><p>新的集成特征打分器（EFG）结果如下表所示，其中Corr.与Dis_Corr都表示的是变量之间的相关系数，只是把目标变量从数值型转换分类变量，RF(Random Forest)也是一样。而LR、RFE则从普通线性回归（OLS）转换为逻辑回归（Logistic Regression）。另外新加入了<strong>支持向量机SVM(Support Vector Machine)</strong>模型。</p><p>与先前的EFG相比较，之前排在前三位的特征变量 <em>alpha_28</em>、<em>AMA</em>、<em>daily_gain_1</em>，现分别排名7、24、19，说明之前集成学习筛选出来的特征变量具有效度。</p><table><thead><tr><th></th><th>Corr.</th><th>Dis_Corr</th><th>LR</th><th>RF</th><th>RFE</th><th>SVM</th><th>Mean</th></tr></thead><tbody><tr><td>D</td><td>1</td><td>0.67</td><td>0.25</td><td>0.57</td><td>0.94</td><td>0.32</td><td>0.62</td></tr><tr><td>low_5</td><td>0.15</td><td>0.14</td><td>1</td><td>0.29</td><td>1</td><td>1</td><td>0.6</td></tr><tr><td>DPO</td><td>0.99</td><td>0.94</td><td>0.19</td><td>0.53</td><td>0.53</td><td>0.3</td><td>0.58</td></tr><tr><td>alpha_23</td><td>0.82</td><td>1</td><td>0.13</td><td>0.53</td><td>0.77</td><td>0.08</td><td>0.55</td></tr><tr><td>CMO</td><td>0.95</td><td>0.69</td><td>0.23</td><td>0.46</td><td>0.81</td><td>0.11</td><td>0.55</td></tr><tr><td>alpha_54</td><td>0.12</td><td>0.08</td><td>0.51</td><td>1</td><td>1</td><td>0.61</td><td>0.54</td></tr><tr><td><strong>alpha_28<br/></strong></td><td>0.1</td><td>0.12</td><td>0.75</td><td>0.52</td><td>0.98</td><td>0.61</td><td>0.52</td></tr><tr><td>ROC</td><td>0.89</td><td>0.83</td><td>0.21</td><td>0.43</td><td>0.39</td><td>0.26</td><td>0.5</td></tr><tr><td>daily_region_1</td><td>0.74</td><td>0.41</td><td>0.24</td><td>0.72</td><td>0.69</td><td>0.24</td><td>0.5</td></tr><tr><td>alpha_101</td><td>0.04</td><td>0.24</td><td>0.49</td><td>0.6</td><td>1</td><td>0.56</td><td>0.48</td></tr><tr><td>close_10</td><td>0.35</td><td>0.51</td><td>0.31</td><td>0.19</td><td>0.92</td><td>0.52</td><td>0.47</td></tr><tr><td>daily_gain_5</td><td>0.14</td><td>0.25</td><td>0.33</td><td>0.76</td><td>0.95</td><td>0.33</td><td>0.45</td></tr><tr><td>price_10</td><td>0.39</td><td>0.39</td><td>0.25</td><td>0.7</td><td>0.76</td><td>0.23</td><td>0.45</td></tr><tr><td>high_10</td><td>0.6</td><td>0.65</td><td>0.39</td><td>0.17</td><td>0.55</td><td>0.26</td><td>0.44</td></tr><tr><td>RVI</td><td>0.95</td><td>0.68</td><td>0.06</td><td>0.53</td><td>0.34</td><td>0.08</td><td>0.44</td></tr><tr><td>close_5</td><td>0.37</td><td>0.33</td><td>0.25</td><td>0.25</td><td>1</td><td>0.31</td><td>0.42</td></tr><tr><td>BIAS</td><td>0.49</td><td>0.58</td><td>0.1</td><td>0.25</td><td>0.85</td><td>0.2</td><td>0.42</td></tr><tr><td>daily_gain_10</td><td>0.14</td><td>0.28</td><td>0.19</td><td>0.78</td><td>0.89</td><td>0.22</td><td>0.41</td></tr><tr><td><strong>daily_gain_1 </strong></td><td>0</td><td>0.12</td><td>0.28</td><td>0.85</td><td>1</td><td>0.17</td><td>0.4</td></tr><tr><td>low_10</td><td>0.35</td><td>0.51</td><td>0.11</td><td>0.15</td><td>0.9</td><td>0.27</td><td>0.39</td></tr><tr><td>daily_region_5</td><td>0.36</td><td>0.35</td><td>0.19</td><td>0.63</td><td>0.6</td><td>0.13</td><td>0.38</td></tr><tr><td>daily_region</td><td>0.7</td><td>0.53</td><td>0.06</td><td>0.73</td><td>0.29</td><td>0.02</td><td>0.38</td></tr><tr><td>opn_5</td><td>0.16</td><td>0.16</td><td>0.34</td><td>0.19</td><td>0.97</td><td>0.41</td><td>0.38</td></tr><tr><td><strong>AMA</strong></td><td>0.69</td><td>0.55</td><td>0.06</td><td>0.39</td><td>0.24</td><td>0.18</td><td>0.37</td></tr><tr><td>MTM_12</td><td>0.66</td><td>0.63</td><td>0.19</td><td>0.2</td><td>0.37</td><td>0.11</td><td>0.36</td></tr><tr><td>amount_1</td><td>0.09</td><td>0.27</td><td>0.23</td><td>0.63</td><td>0.73</td><td>0.24</td><td>0.36</td></tr><tr><td>volume_1</td><td>0.13</td><td>0.29</td><td>0.3</td><td>0.48</td><td>0.74</td><td>0.26</td><td>0.36</td></tr><tr><td>high_5</td><td>0.45</td><td>0.48</td><td>0.17</td><td>0.4</td><td>0.48</td><td>0.11</td><td>0.35</td></tr><tr><td>K</td><td>0.67</td><td>0.48</td><td>0.07</td><td>0.45</td><td>0.31</td><td>0.1</td><td>0.35</td></tr><tr><td>NVI</td><td>0.45</td><td>0.32</td><td>0.11</td><td>0.53</td><td>0.63</td><td>0.09</td><td>0.35</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>TRIX</td><td>0.14</td><td>0.47</td><td>0.11</td><td>0.15</td><td>0.84</td><td>0.18</td><td>0.32</td></tr><tr><td>opn_10</td><td>0.5</td><td>0.57</td><td>0.09</td><td>0.09</td><td>0.35</td><td>0.22</td><td>0.31</td></tr><tr><td>price</td><td>0.08</td><td>0.07</td><td>0.2</td><td>0.57</td><td>0.79</td><td>0.18</td><td>0.31</td></tr><tr><td>daily_opengain</td><td>0</td><td>0.11</td><td>0.23</td><td>0.56</td><td>0.82</td><td>0.13</td><td>0.3</td></tr><tr><td>volume</td><td>0.21</td><td>0.25</td><td>0.11</td><td>0.36</td><td>0.66</td><td>0.17</td><td>0.3</td></tr><tr><td>amount</td><td>0.12</td><td>0.25</td><td>0.17</td><td>0.2</td><td>0.65</td><td>0.32</td><td>0.29</td></tr><tr><td>close_1</td><td>0.03</td><td>0.31</td><td>0.27</td><td>0.18</td><td>0.61</td><td>0.26</td><td>0.28</td></tr><tr><td>OBV</td><td>0.33</td><td>0.37</td><td>0.01</td><td>0.76</td><td>0.1</td><td>0.04</td><td>0.26</td></tr><tr><td>volume_10</td><td>0.17</td><td>0.11</td><td>0.17</td><td>0.56</td><td>0.45</td><td>0.13</td><td>0.26</td></tr><tr><td>PSY</td><td>0.69</td><td>0.6</td><td>0.02</td><td>0</td><td>0.15</td><td>0.01</td><td>0.24</td></tr><tr><td>daily_opengain_5</td><td>0</td><td>0</td><td>0.13</td><td>0.66</td><td>0.5</td><td>0.13</td><td>0.24</td></tr><tr><td>adv_20</td><td>0.06</td><td>0.1</td><td>0.17</td><td>0.27</td><td>0.47</td><td>0.23</td><td>0.23</td></tr><tr><td>price_5</td><td>0</td><td>0.06</td><td>0.1</td><td>0.76</td><td>0.44</td><td>0.06</td><td>0.23</td></tr><tr><td>daily_region_10</td><td>0.3</td><td>0.23</td><td>0.02</td><td>0.68</td><td>0.13</td><td>0.03</td><td>0.23</td></tr><tr><td>volume_5</td><td>0.32</td><td>0.33</td><td>0.02</td><td>0.39</td><td>0.18</td><td>0.08</td><td>0.22</td></tr><tr><td>MACD</td><td>0.12</td><td>0.21</td><td>0.08</td><td>0.41</td><td>0.26</td><td>0.14</td><td>0.21</td></tr><tr><td>alpha_12</td><td>0.03</td><td>0.29</td><td>0.04</td><td>0.73</td><td>0.19</td><td>0</td><td>0.21</td></tr><tr><td>amount_5</td><td>0.31</td><td>0.35</td><td>0</td><td>0.48</td><td>0.02</td><td>0.07</td><td>0.2</td></tr><tr><td>alpha_6</td><td>0.22</td><td>0.14</td><td>0</td><td>0.89</td><td>0</td><td>0.01</td><td>0.2</td></tr><tr><td>high</td><td>0.01</td><td>0.06</td><td>0.15</td><td>0.13</td><td>0.58</td><td>0.21</td><td>0.19</td></tr><tr><td>high_1</td><td>0.15</td><td>0.27</td><td>0.01</td><td>0.41</td><td>0.05</td><td>0.1</td><td>0.17</td></tr><tr><td>amount_10</td><td>0.23</td><td>0.21</td><td>0.06</td><td>0.25</td><td>0.27</td><td>0.01</td><td>0.17</td></tr><tr><td>low</td><td>0.02</td><td>0.06</td><td>0.1</td><td>0.07</td><td>0.56</td><td>0.15</td><td>0.16</td></tr><tr><td>daily_opengain_1</td><td>0.01</td><td>0.04</td><td>0.05</td><td>0.46</td><td>0.32</td><td>0.05</td><td>0.16</td></tr><tr><td>PVI</td><td>0.17</td><td>0.21</td><td>0.02</td><td>0.37</td><td>0.11</td><td>0.03</td><td>0.15</td></tr><tr><td>daily_gain</td><td>0.02</td><td>0.41</td><td>0.01</td><td>0.31</td><td>0.08</td><td>0.06</td><td>0.14</td></tr><tr><td>ForceIndex</td><td>0.01</td><td>0.4</td><td>0.01</td><td>0.33</td><td>0.03</td><td>0.01</td><td>0.13</td></tr><tr><td>daily_opengain_10</td><td>0</td><td>0.09</td><td>0.01</td><td>0.39</td><td>0.06</td><td>0</td><td>0.1</td></tr><tr><td>open</td><td>0.02</td><td>0.06</td><td>0.02</td><td>0.08</td><td>0.16</td><td>0.04</td><td>0.07</td></tr><tr><td>close</td><td>0.01</td><td>0.06</td><td>0.03</td><td>0.1</td><td>0.21</td><td>0.02</td><td>0.07</td></tr></tbody></table><p>67 rows × 8 columns</p><p></p><p>下图是根据新的EFG得出的收益率变化图，可以看出收益率波动较之前稳定，基本在1.9以上，说明<strong>利用分类变量的集成学习模型能更加有效地提升收益率且更加稳定</strong>。
<img src='p/EFG2.png' alt='' /></p><p></p><h3><a name='header-n2703' class='md-header-anchor '></a>6.4 特征提取(降维)</h3><h4><a name='header-n2704' class='md-header-anchor '></a>6.4.1 主成分分析PCA(Principal Component Analysis)</h4><p><strong>主成分分析</strong>旨在利用降维的思想，把多个特征变量转化为少数几个综合指标。其中每个主成分都能够反映原始变量的大部分信息，且所含信息互不重复。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">decomposition</span> <span class="cm-keyword">import</span> <span class="cm-variable">PCA</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span> <span class="cm-keyword">import</span> <span class="cm-variable">cluster</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">h</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">1</span>, <span class="cm-number">68</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">pca</span> = <span class="cm-variable">PCA</span>(<span class="cm-variable">n_components</span>= <span class="cm-variable">i</span>, <span class="cm-variable">copy</span>=<span class="cm-builtin">True</span>, <span class="cm-variable">whiten</span>=<span class="cm-builtin">False</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">p</span> = <span class="cm-variable">pca</span>.<span class="cm-property">fit_transform</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>) </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">input_data</span> = <span class="cm-variable">p</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>) &nbsp; </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span>.<span class="cm-property">fit</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">test_labels</span> = <span class="cm-variable">k_means</span>.<span class="cm-property">predict</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">training_cluster_1_return_rate</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">training_cluster_2_return_rate</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">for</span> <span class="cm-variable">s</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-builtin">len</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">if</span> <span class="cm-variable">k_means</span>.<span class="cm-property">labels_</span>[<span class="cm-variable">s</span>] == <span class="cm-number">1</span> :</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  <span class="cm-variable">training_cluster_1_return_rate</span>.<span class="cm-property">append</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>[<span class="cm-variable">s</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">else</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  <span class="cm-variable">training_cluster_2_return_rate</span>.<span class="cm-property">append</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>[<span class="cm-variable">s</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">if</span> <span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_1_return_rate</span>) <span class="cm-operator">&gt;</span> <span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_2_return_rate</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">h</span>.<span class="cm-property">append</span>(<span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_1_return_rate</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">else</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">h</span>.<span class="cm-property">append</span>(<span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_2_return_rate</span>))</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 476px;"></div></div></div></pre><p><img src='p/pca.png' alt='' /></p><p>如上图所示，这是经过PCA方法处理后的按不同数量主成分组成的数据集得到的收益率数据，可以看到收益率在20个主成分之前有些许波动，而后收益率始终稳定在1.92。与之前根据特征变量数量的收益率图做对比，明显<strong>主成分分析方法得到的收益率更加稳定波动较小</strong>。主成分分析方法平均1.92的收益率，也说明了<strong>EFG筛选后的特征变量最高2.08收益率的有效性</strong>。</p><p></p><h4><a name='header-n2714' class='md-header-anchor '></a>6.4.2  线性判别式分析LDA(Linear Discriminant Analysis)</h4><p>LDA与PCA非常相似也是通过对历史数据进行投影，以保证投影后同一类别的数据尽量靠近，不同类别的数据尽量分开。并生成线性判别模型对新生成的数据进行分离和预测。最大的区别是<strong>LDA在训练数据时加入了结果变量标签，而PCA是无监督学习</strong>。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">discriminant_analysis</span> <span class="cm-keyword">import</span> <span class="cm-variable">LinearDiscriminantAnalysis</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span> <span class="cm-keyword">import</span> <span class="cm-variable">cluster</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">h</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">1</span>, <span class="cm-number">68</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">lda</span> = <span class="cm-variable">LinearDiscriminantAnalysis</span>(<span class="cm-variable">n_components</span>= <span class="cm-variable">i</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">l</span> = <span class="cm-variable">lda</span>.<span class="cm-property">fit_transform</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">data</span>, <span class="cm-variable">hs300</span>.<span class="cm-property">target_c</span>) </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">input_data</span> = <span class="cm-variable">l</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span> = <span class="cm-variable">cluster</span>.<span class="cm-property">KMeans</span>(<span class="cm-variable">n_clusters</span>=<span class="cm-number">2</span>, <span class="cm-variable">max_iter</span> = <span class="cm-number">5000</span>) &nbsp; </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">k_means</span>.<span class="cm-property">fit</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">test_labels</span> = <span class="cm-variable">k_means</span>.<span class="cm-property">predict</span>(<span class="cm-variable">input_data</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">training_cluster_1_return_rate</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">training_cluster_2_return_rate</span> = []</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">for</span> <span class="cm-variable">s</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-builtin">len</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>)):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">if</span> <span class="cm-variable">k_means</span>.<span class="cm-property">labels_</span>[<span class="cm-variable">s</span>] == <span class="cm-number">1</span> :</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  <span class="cm-variable">training_cluster_1_return_rate</span>.<span class="cm-property">append</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>[<span class="cm-variable">s</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-keyword">else</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  <span class="cm-variable">training_cluster_2_return_rate</span>.<span class="cm-property">append</span>(<span class="cm-variable">hs300</span>.<span class="cm-property">target</span>[<span class="cm-variable">s</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">if</span> <span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_1_return_rate</span>) <span class="cm-operator">&gt;</span> <span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_2_return_rate</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">h</span>.<span class="cm-property">append</span>(<span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_1_return_rate</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">else</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">h</span>.<span class="cm-property">append</span>(<span class="cm-builtin">sum</span>(<span class="cm-variable">training_cluster_2_return_rate</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">print</span>(<span class="cm-variable">i</span> , <span class="cm-variable">h</span>[<span class="cm-variable">i</span><span class="cm-operator">-</span><span class="cm-number">1</span>])</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 499px;"></div></div></div></pre><p><img src='p/lda.png' alt='' /></p><p>如上图所示，这是经过LDA方法处理后的按不同数量主成分组成的数据集得到的收益率数据，整体来看收益率非常高，最低的也大于4。对于这一结果，在代码运行的过程中报出了<strong><em>变量存在共线性</em></strong>的警告，所以<strong>该结果不具备有效性</strong>。</p><p></p><h3><a name='header-n2724' class='md-header-anchor '></a>6.5 考虑滑点和交易费用的实际交易策略</h3><p><strong>交易费用</strong>主要包括券商手续费和印花税。券商手续费方面，中国A股市场目前为双边收费，券商手续费系默认值为万分之三，即0.03%，最少5元。印花税方面，印花税对卖方单边征收，对买方不再征收，系统默认为千分之一，即0.1%。（相关代码为set_order_cost(OrderCost(close_tax=0.001, open_commission=0.0003, close_commission=0.0003, min_commission=5), type=&#39;stock&#39;)）</p><p><strong>滑点</strong>是指下单的点位和最后成交的点位有差距。在实战交易中，往往最终成交价和预期价格有一定偏差，因此我们加入了滑点模式来更好地模拟真实市场的表现。在实际策略执行中，我们采用回测平台的默认参数PriceRelatedSlippage(0.00246)，表示实际成交价与预期的价差为当时价格的正负0.123%。</p><p>下面列出的是在<strong>股票量化回测平台joinquant</strong>执行策略的代码，回测时间为<strong>2005-04-01至2017-05-18</strong>，模拟资金为<strong>1000万</strong>，运行频率为<strong>每天</strong>。</p><pre class="md-fences md-end-block" lang="python"> <div class="CodeMirror cm-s-inner CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 4px;"></div><div class="CodeMirror-scrollbar-filler"></div><div class="CodeMirror-gutter-filler"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-height: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># 导入函数库</span></span></pre></div><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">jqdata</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># 初始化函数，设定基准等等</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">initialize</span>(<span class="cm-variable">context</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 设定沪深300作为基准</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">set_benchmark</span>(<span class="cm-string">'000300.XSHG'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 开启动态复权模式(真实价格)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">set_option</span>(<span class="cm-string">'use_real_price'</span>, <span class="cm-builtin">True</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 输出内容到日志 log.info()</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'初始函数开始运行且全局只运行一次'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 过滤掉order系列API产生的比error级别低的log</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># log.set_level('order', 'error')</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">### 股票相关设定 ###</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 股票类每笔交易时的手续费是：买入时佣金万分之三，卖出时佣金万分之三加千分之一印花税, 每笔交易佣金最低扣5块钱</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">set_order_cost</span>(<span class="cm-variable">OrderCost</span>(<span class="cm-variable">close_tax</span>=<span class="cm-number">0.001</span>, <span class="cm-variable">open_commission</span>=<span class="cm-number">0.0003</span>, <span class="cm-variable">close_commission</span>=<span class="cm-number">0.0003</span>, <span class="cm-variable">min_commission</span>=<span class="cm-number">5</span>), <span class="cm-builtin">type</span>=<span class="cm-string">'stock'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">#设置滑点 </span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">set_slippage</span>(<span class="cm-variable">PriceRelatedSlippage</span>(<span class="cm-number">0.00246</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">## 运行函数（reference_security为运行时间的参考标的；传入的标的只做种类区分，因此传入'000300.XSHG'或'510300.XSHG'是一样的）</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment"># 开盘前运行</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">run_daily</span>(<span class="cm-variable">before_market_open</span>, <span class="cm-variable">time</span>=<span class="cm-string">'before_open'</span>, <span class="cm-variable">reference_security</span>=<span class="cm-string">'000300.XSHG'</span>) </span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment"># 开盘时运行</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">run_daily</span>(<span class="cm-variable">market_open</span>, <span class="cm-variable">time</span>=<span class="cm-string">'open'</span>, <span class="cm-variable">reference_security</span>=<span class="cm-string">'000300.XSHG'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment"># 收盘后运行</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">run_daily</span>(<span class="cm-variable">after_market_close</span>, <span class="cm-variable">time</span>=<span class="cm-string">'after_close'</span>, <span class="cm-variable">reference_security</span>=<span class="cm-string">'000300.XSHG'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">g</span>.<span class="cm-property">buy</span> = <span class="cm-error">买入日期</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">g</span>.<span class="cm-property">sell</span> = <span class="cm-error">卖出日期</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">## 开盘前运行函数 &nbsp; &nbsp; </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">before_market_open</span>(<span class="cm-variable">context</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 输出运行时间</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'函数运行时间(before_market_open)：'</span><span class="cm-operator">+</span><span class="cm-builtin">str</span>(<span class="cm-variable">context</span>.<span class="cm-property">current_dt</span>.<span class="cm-property">time</span>()))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 要操作的股票：沪深300指数（g.为全局变量）</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">g</span>.<span class="cm-property">security</span> = <span class="cm-string">'000300.XSHG'</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">## 开盘时运行函数</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">market_open</span>(<span class="cm-variable">context</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'函数运行时间(market_open):'</span><span class="cm-operator">+</span><span class="cm-builtin">str</span>(<span class="cm-variable">context</span>.<span class="cm-property">current_dt</span>.<span class="cm-property">time</span>()))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">security</span> = <span class="cm-variable">g</span>.<span class="cm-property">security</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 取得当前的现金</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">cash</span> = <span class="cm-variable">context</span>.<span class="cm-property">portfolio</span>.<span class="cm-property">available_cash</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">dt</span>=<span class="cm-variable">context</span>.<span class="cm-property">current_dt</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 如果上一时间点价格高出五天平均价1%, 则全仓买入</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">if</span> <span class="cm-builtin">str</span>(<span class="cm-variable">dt</span>)[:<span class="cm-number">10</span>] <span class="cm-keyword">in</span> <span class="cm-variable">g</span>.<span class="cm-property">buy</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-comment"># 记录这次买入</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">"买入 %s"</span> <span class="cm-operator">%</span> (<span class="cm-variable">security</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-comment"># 用所有 cash 买入股票</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">order_value</span>(<span class="cm-variable">security</span>, <span class="cm-variable">cash</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment"># 如果上一时间点价格低于五天平均价, 则空仓卖出</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">if</span> <span class="cm-builtin">str</span>(<span class="cm-variable">dt</span>)[:<span class="cm-number">10</span>] <span class="cm-keyword">in</span> <span class="cm-variable">g</span>.<span class="cm-property">sell</span>:</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-comment"># 记录这次卖出</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">"卖出 %s"</span> <span class="cm-operator">%</span> (<span class="cm-variable">security</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-comment"># 卖出所有股票,使这只股票的最终持有量为0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">order_target</span>(<span class="cm-variable">security</span>, <span class="cm-number">0</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment cm-error">## 收盘后运行函数  </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">after_market_close</span>(<span class="cm-variable">context</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-builtin">str</span>(<span class="cm-string">'函数运行时间(after_market_close):'</span><span class="cm-operator">+</span><span class="cm-builtin">str</span>(<span class="cm-variable">context</span>.<span class="cm-property">current_dt</span>.<span class="cm-property">time</span>())))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">#得到当天所有成交记录</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">trades</span> = <span class="cm-variable">get_trades</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-keyword">for</span> <span class="cm-variable">_trade</span> <span class="cm-keyword">in</span> <span class="cm-variable">trades</span>.<span class="cm-property">values</span>():</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'成交记录：'</span><span class="cm-operator">+</span><span class="cm-builtin">str</span>(<span class="cm-variable">_trade</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'一天结束'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-variable">log</span>.<span class="cm-property">info</span>(<span class="cm-string">'##############################################################'</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 0px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1496px;"></div></div></div></pre><p></p><p>下图为该策略（考虑交易费用和滑点）的实际回测结果，可以看出结果极为不理想，累积收益率是负的，而同期基准——沪深300指数的收益率达到238.64%。说明<strong>这个策略的实际收益率比一直持有沪深300的最简单策略都差距甚远</strong>。
<img src='p/backtest1.png' alt='' /></p><p></p><p>这张图表示的是不考虑交易费用和滑点的策略实际回测结果，可以看出较之前的回测结果，收益率显著提升。由于该策略进出操作频繁，实际收益容易受到滑点和交易费用的影响，所以当不考虑时收益率上升明显，但是其累积收益率也只是高出基准收益9%不到。这与之前预估的<strong>对数收益率2.08</strong>（转换到实际收益率为700%，即从1000点升到8000点）。<strong>所以该策略的实际可行性并不是很高</strong>。</p><p><img src='p/backtest2.png' alt='' /></p><p></p><h2><a name='header-n2745' class='md-header-anchor '></a>7.结论</h2><p>本文创新性地把特征工程的知识运用到股票市场中，在基于沪深300指数原始数据中组合计算挖掘出总共67个特征变量，并经过特征选择方法中的集成特征打分器筛选出3个特征变量，最终基于K-means聚类分析后的结果，提出了基准的持续稳定盈利择时策略。并对该策略模型进行了一系列的稳定性检验，说明集成学习的模型能有效提升收益率和稳定性，但是策略的实际可行性还较低，需要未来做更进一步的相关研究。</p><p>目前据资料所得，国内市场量化交易策略只占市场份额1%不到，而美国市场已经发展到交易额的30%，这说明国内金融交易市场未来的量化交易非常可期，势必会迎来一轮大发展。最近微软AI首席科学家、IEEE Fellow邓力从微软离职加盟对冲基金巨头Citadel任首席人工智能官，也预示着人工智能在股票市场应用，各种量化交易研究平台，各个交易策略，各种alpha量化因子库势必造就一波别开生面的景象。</p><p></p><h2><a name='header-n2752' class='md-header-anchor '></a>参考资料</h2><ol start='' ><li>jasonfreak， 使用sklearn做单机特征工程， 博客园 <a href='http://www.cnblogs.com/jasonfreak/p/5448385.html' title='使用sklearn做单机特征工程 '>http://www.cnblogs.com/jasonfreak/p/5448385.html</a></li><li>JasonDing， 【特征工程】特征选择与特征学习， 简书 <a href='http://www.jianshu.com/p/ab697790090f' title='【特征工程】特征选择与特征学习'>http://www.jianshu.com/p/ab697790090f</a></li><li>李斌等， ML-TEA: 一套基于机器学习和技术分析的量化投资算法， 系统工程理论与实践，forthcoming</li><li>Distance correlation， wikipedia <a href='https://en.wikipedia.org/wiki/Distance_correlation' title='Distance correlation'>https://en.wikipedia.org/wiki/Distance_correlation</a></li><li>江嘉键，  特征选择方法探析-沪深300指数的集成特征选择和聚类分析，ricequant<a href='https://www.ricequant.com/community/topic/1603/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90-%E6%B2%AA%E6%B7%B1300%E6%8C%87%E6%95%B0%E7%9A%84%E9%9B%86%E6%88%90%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E5%92%8C%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90' title='特征选择方法探析—沪深300指数的集成特征选择和聚类分析'>https://www.ricequant.com/community/topic/1603/特征选择方法探析-沪深300指数的集成特征选择和聚类分析</a></li><li>江嘉键， 沪深300指数的特征工程和聚类分析-以WorldQuant Formulaic 101 Alphas为例，ricequant<a href='https://zhuanlan.zhihu.com/p/21337419' title='沪深300指数的特征工程和聚类分析-以WorldQuant Formulaic 101 Alphas为例'>https://zhuanlan.zhihu.com/p/21337419</a></li><li>陆东旭， Ipython Notebook Research Alpha下机器学习一瞥，关于跌跌涨涨的思考，ricequant <a href='https://www.ricequant.com/community/topic/103' title='Ipython Notebook Research Alpha下机器学习一瞥，关于跌跌涨涨的思考'>https://www.ricequant.com/community/topic/103</a></li><li>Edwin Jarvis， 干货：结合Scikit-learn介绍几种常用的特征选择方法 <a href='http://dataunion.org/14072.html' title='干货：结合Scikit-learn介绍几种常用的特征选择方法 '>http://dataunion.org/14072.html</a></li><li>Kakashadze Z. 101 Formulaic Alphas[J]. Social Science Electronic Publishing, 2016, 2016(84):72–81.</li></ol><p></p><h2><a name='header-n2783' class='md-header-anchor '></a>疑问</h2><ol start='' ><li><strong>各个基模型的调参问题</strong>。</li><li><strong>聚类分析的合理性以及为什么呈现V型</strong></li><li><strong>集成特征打分器的原理可行性而且随机森林自身包含了集成学习</strong></li><li><strong>Lasso_BIC 的系数全为0问题</strong></li><li><strong>策略在实际执行结果与聚类分析结果相差巨大</strong></li></ol><p></p><h2><a name='header-n2802' class='md-header-anchor '></a>附录</h2><h3><a name='header-n2803' class='md-header-anchor '></a>附录一 —— 基础变量的名称和公式</h3><table><thead><tr><th>指标名称</th><th>计算公式(O:开盘价;C:收盘价;L:最低价;H:最高价;V:交易量;A:交易总额）</th></tr></thead><tbody><tr><td>price</td><td>A/V</td></tr><tr><td>daily_gain</td><td>ln(C)-ln(O)</td></tr><tr><td>daily_region</td><td>ln(H)-ln(L)</td></tr><tr><td>daily_opengain</td><td>ln(O)-前一日ln(O)</td></tr></tbody></table><p></p><h3><a name='header-n2822' class='md-header-anchor '></a>附录二  ——  衍生经典技术指标的名称和公式</h3><table><thead><tr><th>指标类型</th><th>指标名称</th><th>计算公式(O:开盘价;C:收盘价;L:最低价;H:最高价;）</th><th>指标参数</th></tr></thead><tbody><tr><td>趋势指标</td><td>MACD</td><td>EMA(n)=前一日 EMA(n)<em>(n-l)/(n+l)+C</em>2/(n+l);</td><td>q=12;</td></tr><tr><td></td><td></td><td>DIF=EMA(q)-EMA(p);</td><td>p=26;</td></tr><tr><td></td><td></td><td>DEA=前一日 DEA<em>(t-1)/(t+1)+DIF</em>2/(t+1);</td><td>t=9;</td></tr><tr><td></td><td>AMA</td><td>DMA(n)=n日平均值一m日平均值；</td><td>n=10;</td></tr><tr><td></td><td></td><td>AMA(n)=n日DMA 平均值；</td><td>m=50;</td></tr><tr><td></td><td>TRIX</td><td>TRIX=(EMA(n)-前一日 EMA(n))/EMA(n)*100;</td><td>n=3;</td></tr><tr><td></td><td>VHF</td><td>VHF=(H(n)-L(n))/SUM(ABS(C-前一日 C),n);</td><td>n=28;</td></tr><tr><td></td><td>RVI</td><td>CO=C-O;HL=H-L; V1=(CO+2<em>前一日CO+2</em>前两日CO+前三日CO)/6; V1=(HL+2<em>前一日HL+2</em>前两日HL+前三日HL)/6; S1=SUM(V1, n); S2=SUM(V2, n); RVI=S1/S2</td><td>n=10;</td></tr><tr><td>震荡指标</td><td>KDJ</td><td>K=(q-1)/q* 前一日K+1/q*RSV;</td><td>q=3;</td></tr><tr><td></td><td></td><td>D=(p-1)/p* 前一日D+1/p*K;</td><td>p=4;</td></tr><tr><td></td><td></td><td>J=3K-2D;</td><td></td></tr><tr><td></td><td>BIAS</td><td>MA(n) = ∑Ci/n;BIAS(n) = (C - MA(n))/MA(n)</td><td>n=12;</td></tr><tr><td></td><td>ForceIndex</td><td>ForceIndex=(C-前一日 C)* 成交量；</td><td></td></tr><tr><td>超买超卖指标</td><td>VR</td><td>VR(n)=SUM(上升日成交量,n)ASUM(下降日成交量,n);</td><td>n=12;</td></tr><tr><td></td><td>DPO</td><td>DPO=C-前(n/2+1)日的MA(n);</td><td>n=20;</td></tr><tr><td></td><td>NVI</td><td>如果今日成交量大于昨日成交量： NVI=前一日 NVI;</td><td></td></tr><tr><td></td><td>PVI</td><td>如果昨日成交量大于今日成交量： NVI=前一日 NVI<em>(1+(C-前一日 C)/前一日 C) PVI(n+1)=PVI(n)+sign(n+1)</em>RC(n+1); RC(n+1) = [C(n+1)-C(n)]/C(n);</td><td>无</td></tr><tr><td></td><td>ROC</td><td>AX=C —前N天C; BX=前N天C; ROC=AX/BX;</td><td>N=12;</td></tr><tr><td>能量指标</td><td>OBV</td><td>如果C&gt;前一日C:基期OBV加上本日成交量为本日OBV；否则，基期OBV减去本日成交量为本日OBV。</td><td></td></tr><tr><td></td><td>PSY</td><td>PSY=n日内的上涨天数/n* 100%;</td><td>n=12</td></tr><tr><td>动量</td><td>MTM</td><td>MTM(n)=C-前Lag日C</td><td>Lag=12;</td></tr><tr><td></td><td>CMO</td><td>CMO=(Su-Sd)*100/(Su+Sd);其中：Su是今日收盘价与昨日收盘价(上涨日）差值加总.若当日下跌，则增加值为0; Sd是今日收盘价 与昨日收盘价(下跌日)差值的绝对值加总.若当日上涨，则增加值为0;</td><td></td></tr></tbody></table><p></p><h3><a name='header-n2941' class='md-header-anchor '></a>附录三 —— 阿尔法变量的名称和公式</h3><table><thead><tr><th>指标名称</th><th>计算公式(O:开盘价;C:收盘价;L:最低价;H:最高价;V:交易量）</th></tr></thead><tbody><tr><td>alpha#6</td><td>(-1 * correlation(O, V, 10))</td></tr><tr><td>alpha#12</td><td>(sign(delta(V, 1)) * (-1 * delta(C, 1)))</td></tr><tr><td>alpha#23</td><td>(((sum(H, 20) / 20) &lt; H) ? (-1 * delta(H, 2)) : 0)</td></tr><tr><td>alpha#28</td><td>scale(((correlation(adv20, L, 5) + ((H + L) / 2)) - C))</td></tr><tr><td>alpha#54</td><td>((-1 * ((L - C) * (O^5))) / ((L- H) * (C^5)))</td></tr><tr><td>alpha#101</td><td>((C - O) / ((H - L) + .001))</td></tr></tbody></table><p>其中：</p><ul><li>x ? y : z，sign(x) are standard definitions</li><li>correlation(x, y, d) = time-serial correlation of x and y for the past d days</li><li>scale(x, a) = rescaled x such that sum(abs(x)) = a (the default is a = 1)</li><li>delta(x, d) = today’s value of x minus the value of x d days ago</li></ul></div>
</body>
</html>